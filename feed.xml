<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="//srikanth.sastry.name/feed.xml" rel="self" type="application/atom+xml" /><link href="//srikanth.sastry.name/" rel="alternate" type="text/html" /><updated>2022-06-18T12:32:38+00:00</updated><id>//srikanth.sastry.name/feed.xml</id><title type="html">Srikanth Sastry</title><subtitle>A personal website</subtitle><author><name>Srikanth Sastry</name><email>srikanth@sastry.name</email></author><entry><title type="html">Defining unit tests: two schools of thought</title><link href="//srikanth.sastry.name/defining-unit-tests-two-schools-of-thought/" rel="alternate" type="text/html" title="Defining unit tests: two schools of thought" /><published>2022-06-18T00:00:00+00:00</published><updated>2022-06-18T00:00:00+00:00</updated><id>//srikanth.sastry.name/defining-unit-tests-two-schools-of-thought</id><content type="html" xml:base="//srikanth.sastry.name/defining-unit-tests-two-schools-of-thought/"><![CDATA[<h3 id="definitions-what-is-a-unit-test">Definitions: What is a unit test?</h3>
<p><img src="/images/london-detroit.jpg" alt="" /></p>

<p>There are several definitions for unit tests. <a href="https://www.artofunittesting.com/definition-of-a-unit-test">Roy Osherove</a> defines it as “piece of code that invokes a unit of work in the system and then checks a single assumption about the behavior of that unit of work”; Kent Beck turns the idea of defining unit tests on it’s head by <a href="https://tidyfirst.substack.com/p/desirable-unit-tests">simply stating a list of properties</a>, and any code that satisfies those properties in a “unit test”.</p>

<p>I like Vladimir Khorikov’s definition of a unit test in his book <a href="https://www.manning.com/books/unit-testing">Unit Testing Principles, Practices, and Patterns</a>. According to him, a unit test is a piece of code that (1) verifies a unit of software, (2) in isolation, and (3) quickly. The above definition only balkanizes a <em>unit test</em> into three undefined terms: (1) unit of software, (2) isolation, and (3) quick/fast/speed. Of the three, the third one is the easiest to understand intuitively. Being <em>fast</em> simply means that you should be able to run the test in real time and get the results quickly enough to enable interactive iteration of modifying the unit of software you are changing. However, the other two terms: <em>unit of software</em>, and <em>isolation</em> merit more discussion.</p>

<h3 id="are-you-from-detroit-or-london">Are you from Detroit, or London?</h3>

<p>In fact, there are two schools of thought around how the above two terms should be defined. The ‘original/classic/Detroit’ school, and the ‘mockist/London’ school. Not surprisingly, the school of thought you subscribe to has a significant impact on how you write unit tests. For a more detailed treatment of the two schools of thought, I suggest Martin Folwer’s <a href="https://martinfowler.com/articles/mocksArentStubs.html#ClassicalAndMockistTesting">excellent article on the subject of Mocks and Stubs</a>. Chapter 2 of Khorikov’s book <a href="https://www.manning.com/books/unit-testing">Unit Testing Principles, Practices, and Patterns</a> also has some good insights into it. I have distilled their contents as it pertains to unit test definitions.</p>

<h4 id="the-detroit-school">The Detroit School</h4>

<p>The Classical or Detroit school of thought originated with Kent Beck’s “<a href="https://www.oreilly.com/library/view/test-driven-development/0321146530/">Test Driven Development</a>”.</p>

<p><strong>Unit of software.</strong> According to this school, the unit of software to test is a “behavior”. This behavior could be implemented in a single class, or a collection of classes. The important property here is that the the code that comprises the unit must be (1) internal to the software, (2) connected with each other in the dependency tree, and (3) not shared by another other part of the software.</p>

<p>Thus, a unit of software cannot include external entities such as databases, log servers, file systems etc. They also cannot include external (but local) libraries such as system time and timers. Importantly, it is <em>ok</em> to include a class that depends on another class via a private non-shared dependency.</p>

<p><strong>Isolation.</strong> Given the above notion of a “unit” of software, isolation simply means that the test is not dependent on anything outside that unit of software. In practical terms, it means that a unit test needs to replace all external and shared dependencies with <a href="/mocks-stubs-andhow-to-use-them/">test doubles</a>.</p>

<h4 id="the-london-school">The London School</h4>

<p>The mockist or London school of thought was popularized by <a href="https://www.linkedin.com/in/stevefreeman">Steve Freeman</a> (<a href="https://twitter.com/sf105">twitter</a>) and <a href="http://www.natpryce.com/bio.html">Nat Pryce</a> in their book “<a href="http://growing-object-oriented-software.com/">Growing Object- Oriented Software, Guided by Tests</a>”.</p>

<p><strong>Unit of Software.</strong> Given the heavy bias Object-Oriented software, unsurprisingly, the unit of software for a unit test is a single class (in some cases, it can be a single method). This is strictly so. ANy other class that this the ‘class under test’ depends on cannot be part of the unit being tested.</p>

<p><strong>Isolation.</strong> What follows from the above notion of a “unit” is that <em>everything</em> that is not the class under test must be replaced by test doubles. If you are instantiating another class inside the class under test, then you must replace that instantiation with an injected instance or a factory that can be replaced with a test double in the tests.</p>

<p>Here is a quick summary of the definitions of a unit tests under the two schools.</p>

<table>
  <thead>
    <tr>
      <th>School</th>
      <th>Unit</th>
      <th>Isolation</th>
      <th>Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Classical</td>
      <td>Behavior</td>
      <td>mock out shared and external dependencies</td>
      <td>‘fast’</td>
    </tr>
    <tr>
      <td>London</td>
      <td>Class</td>
      <td>out all dependencies (internal, external, shared, etc.)</td>
      <td>‘fast’</td>
    </tr>
  </tbody>
</table>

<h3 id="what-does-this-mean">What does this mean?</h3>

<p>The school of thought you subscribe to can have a significant impact on your software design and testing. There is nothing I can say here that hasn’t already been explained by Martin Fowler in his article “<a href="https://martinfowler.com/articles/mocksArentStubs.html">Mocks aren’t stubs</a>”. So, I highly recommend you read it for yourself.</p>]]></content><author><name>Srikanth Sastry</name><email>srikanth@sastry.name</email></author><category term="professional" /><category term="unit tests" /><category term="software engineering" /><category term="classical school" /><category term="london school" /><summary type="html"><![CDATA[A unit test is a piece of code that verifies a "unit" of software, in "isolation", and quickly. There are two schools of thought on the notion of "unit" and "isolation", and that makes all the difference.]]></summary></entry><entry><title type="html">Primary attributes of unit test suites and their tradeoffs</title><link href="//srikanth.sastry.name/unit-test-attributes-and-their-trade-offs/" rel="alternate" type="text/html" title="Primary attributes of unit test suites and their tradeoffs" /><published>2022-06-13T00:00:00+00:00</published><updated>2022-06-13T00:00:00+00:00</updated><id>//srikanth.sastry.name/unit-test-attributes-and-their-trade-offs</id><content type="html" xml:base="//srikanth.sastry.name/unit-test-attributes-and-their-trade-offs/"><![CDATA[<p><img src="/images/accuracy-completeness-speed.png" alt="" />
Unit test suites have three primary attributes.</p>

<ol>
  <li>accuracy,</li>
  <li>completeness, and</li>
  <li>speed.</li>
</ol>

<p><em>Accuracy</em> says that if a test fails, then there is a bug. <em>Completeness</em> says that if there is a bug, then a unit test will fail. <em>Speed</em> says that tests will run ‘fast’. These three attributes are in opposition with each other, and you can only satisfy any two of the three attributes!</p>

<p>Before discussing these attributes, it is important to note that they are not properties of test suite at rest, but rather, of the test suite during changes. That is, these attributes are measured only when you are making changes to the code and running the test suite in response to those changes. Also, these attributes are not applicable to a single unit test. Instead, they apply to the test suite as a whole. Furthermore, the quality of your test suite is determined by how well the suite measures up along these attributes.</p>

<h3 id="attributes-descriptions">Attributes’ descriptions</h3>
<p>Let’s describe each of these attributes, and then we can see any unit test suite is forced to trade off these attributes.</p>

<ol>
  <li><em>Accuracy.</em> It is a measure of robustness of the test suite to changes in the production code. If you make a change to the production code <em>without changing your unit tests</em>, and your test suite has a failure, then how likely is it that your changes introduced a bug? Accuracy is a measure of this likelihood. High quality unit tests typically have very good accuracy. If your test suite has poor accuracy, then it suggests that either your tests are brittle, they are actually testing implementation details instead of functionality, or your production code is poorly designed with leaky abstractions. Inaccurate tests reduce your ability to detect regressions. They fail to provide early warning when a diff breaks existing functionality (because the developer cannot be sure that the test failure is a genuine bug, and not an artifact of test brittleness). As a result, developers are more likely to ignore test failure, or modify the tests to make it ‘pass’, and thus introduce bugs in their code.</li>
  <li><em>Completeness</em>. This is a measure of how comprehensive the test suite really is. If you make a change to the production code <em>without changing your unit tests</em>, and you introduce a bug in <em>an existing functionality</em>, then how likely is it that your test suite will fail? Completeness is a measure of this likelihood. A lot of the test coverage metrics try to mimic the completeness of your test suite. However, <a href="/do-not-index-in-test-coverage/">we have seen how coverage metrics are often a poor proxy for completeness</a>.</li>
  <li><em>Speed</em>. This is simply a measure of how quickly a test suite runs. If tests are hermetic with the right use of <a href="/mocks-stubs-andhow-to-use-them/">test doubles</a>, then each test runs pretty quickly. However, if the tests are of poor quality or the test suite is very large, then they can get pretty slow. It is most noticeable when you are iterating on a feature, and with each small change, you need to run the test suite that seems to take forever to complete. Slow tests can have a disproportionate impact on developer velocity. It will make developer less likely to run tests eagerly, it increases the time between iterations, and it increases the CI/CD latency to where the gap between your code landing and the changes making it to prod can be unreasonably large. If this gets bad enough, it will discourage developers from running tests as needed, and thus allow bugs to creep in.</li>
</ol>

<h3 id="attribute-constraints-and-trade-offs">Attribute constraints and trade offs</h3>

<p>There is a tension among attributes, and how these attributes contribute to overall unit test suite quality.</p>

<p>Among accuracy, completeness, and speed, you cannot maximize all three; that is, you cannot have a <em>fast</em> test suite that will fail if <em>and only if</em> there is a bug. Maximizing any two will minimize the third.</p>
<ul>
  <li>A prefect test suite with high accuracy and completeness will inevitably be huge, and thus very slow.</li>
  <li>A fast test suite with high accuracy will often only test only the most common user journeys, and thus be incomplete.</li>
  <li>A test suite with very high coverage is often made ‘fast’ through extensive use of test doubles and ends up coupling tests with the implementation details, which makes the tests brittle, and therefore inaccurate.</li>
</ul>

<h3 id="whats-the-right-trade-off">What’s the right trade off?</h3>
<p><img src="/images/balance-scale.jpg" alt="Image not found: /images/balance-scale.jpg" title="Image not found: /images/balance-scale.jpg" /></p>

<p>A natural follow up to the trade offs among accuracy, completeness, and speed is <em>“What is the right trade off?”</em>. It helps to notice that, empirically, we are always making this trade off and naturally settling on some point in the trade-off surface. What is this natural resting point for these trade offs? Let’s examine a few things to help us answer the above question.</p>

<ol>
  <li>From experience, we know that bugs in software are inevitable, and we have learned to deal with it. While bug-free code might be the ideal, no one reasonably expects bug-free software, and we accept some level of incorrectness in our implementations.</li>
  <li>Flaky/brittle tests can have very significant negative consequences. Such tests are inherently untrustworthy, and therefore, serve no useful purpose. In the end, we tend to ignore such tests, and for all practical purposes they just don’t exist in our test suite.</li>
  <li>While extremely slow tests are an issue, we have figured out ways to improve test speeds through infrastructure developments. For instance,our CI/CD systems can run multiple tests in the test suite in parallel, and thus we are delayed only by the slowests tests in the test suite; we have figured out how to prune the affected tests in a diff by being smart about the build and test targets affected by the changes, and thus, we need not run the entire test suite for a small change; the machines that execute tests have just gotten faster, thus alleviating some of the latency issues, etc.</li>
</ol>

<p>From the above three observations, we can reasonably conclude that we cannot sacrifice accuracy. Accurate tests are the bedrock of trustworthy (and therefore, useful) test suites. Once we maximize accuracy, that leaves us with completeness and speed. Here there is a sliding scale between completeness and speed, and we could potentially rest anywhere on this scale.</p>

<p>So, is it ok to rest anywhere on the tradeoff spectrum between completeness and accuracy? Not quite. If you dial completeness all the way up and ignore speed, then you end up with a test suite that no one wants to run, and therefore, not useful at all. On the other hand, if you ignore completeness in favor of speed, then you are likely going to see a lot of regressions in your software and completely undermine consumer confidence in your product/service. In effect, <strong>the quality of your test suite is determined by the lowest score among the three attributes.</strong> Therefore, it is important to rest between completeness and speed, depending on the tolerance to errors and the minimum developer velocity you can sustain. For instance, if you are developing software for medical imaging, then your tolerance to errors is very very low, and so you should be favoring completeness at the expense of speed (and this is evident in how long it takes to make changes to software in the area of medical sciences). On the other hand, if you are building a web service that can be rolled back to a safe state quickly and with minimal external damage, then you probably want to favor speed over completeness (but only to a point; remember that your test quality is now determined by the completeness, or the lack thereof).</p>

<p>Thus, in conclusion, always maximize accuracy, and trade off between completeness and speed, depending on your tolerance of failures in production.</p>]]></content><author><name>Srikanth Sastry</name><email>srikanth@sastry.name</email></author><category term="professional" /><category term="unit tests" /><category term="software engineering" /><summary type="html"><![CDATA[Unit test suites have three attributes: accuracy, completeness, and speed. You can maximize any two, but not all three. So how do you choose what to maximize?]]></summary></entry><entry><title type="html">The big WHY about unit tests</title><link href="//srikanth.sastry.name/the-big-why-about-unit-tests/" rel="alternate" type="text/html" title="The big WHY about unit tests" /><published>2022-06-06T00:00:00+00:00</published><updated>2022-06-06T00:00:00+00:00</updated><id>//srikanth.sastry.name/the-big-why-about-unit-tests</id><content type="html" xml:base="//srikanth.sastry.name/the-big-why-about-unit-tests/"><![CDATA[<p><img src="/images/question_mark_person_leaning.png" alt="Why unit test?" />
When you ask “why do we write need unit tests?”, you will get several answers including</p>
<ul>
  <li>To find common bugs in your code</li>
  <li><a href="/the-merits-of-unit-tests-part-2/">As protection against regression</a></li>
  <li><a href="/merits-of-unit-tests-part-1/">To act as a de facto documentation of your code</a></li>
  <li><a href="/the-merits-of-unit-tests-part-3/">To help improve software design</a></li>
  <li><a href="/unit-tests-ftw-part-4/">To help debug issues in production</a></li>
  <li><a href="/merits-of-unit-tests-part-5/">Improve your APIs’ usability</a></li>
  <li>etc.</li>
</ul>

<p>These seems like a collection of very good reasons, but it seems inelegant to state that the common phenomenon of unit testing has such disparate causes. 
There must be a ‘higher’ cause for writing unit tests. I argue that this cause is “maintainability”.</p>

<h3 id="maintainability">Maintainability</h3>
<p><img src="/images/website-wrench-cog.png" alt="Maintainable software" />
Here is a potentially provocative statement; “The final cause of unit tests is software maintainability”.
To put it differently, if your software was immutable and could not be altered in any way, then that software does not need any unit tests.</p>

<p>Given that almost all software is mutable, unit tests exist to ensure that we can mutate the software to improve upon its utility in a sustainable manner. All the aforementioned answers to the question “why do we write unit tests” are ultimately subsumed by the cause of maintainability.</p>

<ul>
  <li>Unit tests help you find bugs in your code, thus allowing safe mutations that add functionality.</li>
  <li>Unit tests protect against regression, especially when refactoring, thus allowing safe mutation of the software in preparation for functional changes.</li>
  <li>Unit tests act as de facto documentation. It allows developers who change the code to communicate across time and space on how best to use existing code for mutating other code.</li>
  <li>Unit tests help improve software design. It some code/class is difficult to unit test, then the software design is poor. So, you iterate until unit testing becomes easier.</li>
  <li>Unit test help improve the usability of your API. Unit tests are the first customers of your API. If unit tests using your API are inelegant, then you iterate towards more usuable APIs. A more usable API is often a more used API, and thus, aids software evolution.</li>
</ul>

<p>Interestingly, looking at maintainability as the primary motivation for unit tests allows us to look at some aspects of unit tests differently.</p>

<h3 id="looking-at-unit-tests-differently">Looking at unit tests differently</h3>

<h4 id="unit-tests-incur-a-maintenance-cost">Unit tests incur a maintenance cost.</h4>
<p><img src="/images/calculator-sheet.png" alt="" /></p>

<p>If it code incurs a maintenance cost, and unit tests help reduce that cost, then you can naturally ask the following; <em>since unit tests are also code, do they not incur a maintenance cost?</em></p>

<p>Obviously the answer to the question above is an unequivocal “yes!”. Thus, unit tests are only useful if the cost of maintaining them exceeds the savings they provide as a buttress against production code. This observation has significant implications for how to design and write unit tests. For instance, unit tests must be simple straight line code that is human readable, even at the expense of performance and redundancy. See the post on <a href="https://srikanth.sastry.name/dry-unit-tests-are-bad/">DRY unit tests</a> for a more detailed treatment on this topic.</p>

<h4 id="unit-tests-can-have-diminishing-returns">Unit tests can have diminishing returns.</h4>
<p><img src="/images/down-graph-arrow.png" alt="" /></p>

<p>If unit tests incur a maintenance cost, then their utility is the difference between the maintainability they provide and the cost they incur. Since software is a living/evolving entity, both this utility changes over time. Consequently, if you are not careful with your tests, then could become the proverbial Albatross across your neck.
   Consequently, it is important to tend to your unit test suite and pay attention when the utility of a test starts to diminish. Importantly, refactor your tests to ensure that you do not hit the point of diminishing, or even negative returns on your unit test.</p>

<h4 id="unit-tests-should-be-cognitively-simple">Unit tests should be cognitively simple.</h4>
<p><img src="/images/simple-chair-wall-painting-white.png" alt="" /></p>

<p>An almost necessary way to reduce the maintenance cost of a unit tests is to make it very simple to read and understand. It helps with maintenance in two ways. First, it makes it easy to understand the intent of the test, and the coverage that the test provides. Second, it makes it easy to modify the test (if needed) without having to worry about an unintended consequences such modifications might have; a degenerate case is that of tests that have hit the point of diminishing returns; more simple a test is, the easier it is to refactor and/or delete it. See the post on <a href="https://srikanth.sastry.name/dry-unit-tests-are-bad/">DRY unit tests</a> for mote details.</p>

<h4 id="a-bad-unit-test-is-worse-than-no-unit-test">A bad unit test is worse than no unit test.</h4>
<p><img src="/images/sad-face-spray-paint.png" alt="" /></p>

<p>If unit test incur a maintenance cost, then a bad unit test has all the costs associated with unit tests and none of the benefits. It is a net loss. Your code base is much better off without that unit test. In fact, a bad unit test can have an even higher cost if it sends developers on a wild goose chase looking for bugs when such unit tests fail. So, unless a unit test is of high quality, don’t bother with it. Just delete it.</p>

<h4 id="a-flaky-unit-test-is-the-worst">A flaky unit test is the worst.</h4>
<p><img src="/images/yes-no.png" alt="" /></p>

<p>This is a corollary of the previous observation, but deserves some explanation. Flaky tests have the side effect of undermining the trust in the entire test suite. If a test is flaky, then developers are more likely to ignore red builds, because ‘that flaky test is the culprit, and so the failure can be ignored’. However, inevitably, some legitimate failure does occur. But, at this point, developers have been conditioned to ignore build/test failures. Consequently, a buggy commit makes it’s way to prod and causes a regression, which would never have happened if you didn’t have that flaky test.</p>]]></content><author><name>Srikanth Sastry</name><email>srikanth@sastry.name</email></author><category term="professional" /><category term="unit tests" /><category term="testing" /><category term="software engineering" /><summary type="html"><![CDATA[The ultimate "why" for unit tests is maintainability. All the arguments for having robust, good quality unit tests comes down to the following. Unit tests help keep your production code maintainable. Looking at maintainability as the primary motivation for unit tests allows us to look at some aspects of unit tests differently.]]></summary></entry><entry><title type="html">Unit test the brains and not the nerves</title><link href="//srikanth.sastry.name/unit-test-the-brains-and-not-the-nerves/" rel="alternate" type="text/html" title="Unit test the brains and not the nerves" /><published>2022-05-31T00:00:00+00:00</published><updated>2022-05-31T00:00:00+00:00</updated><id>//srikanth.sastry.name/unit-test-brains-and-not-nerves</id><content type="html" xml:base="//srikanth.sastry.name/unit-test-the-brains-and-not-the-nerves/"><![CDATA[<p><em>Note: This is inspired from the book “<a href="https://www.manning.com/books/unit-testing">Unit Testing: Principles, Practices, and Patterns</a>” by Vladimir Khorikov.</em></p>

<p><img src="/images/brain-magnifying-glass.png" alt="brain" /></p>

<p>Unit tests are typically your first line of defense against bugs. So, it is tempting to add unit tests for all functionality that your code supports. But that begs the following question. “Why do we need integration and end-to-end tests?”</p>

<h2 id="categorizing-production-code">Categorizing production code</h2>
<p>To better understand the primary motivations for unit tests vs. integration (and end-to-end) tests, it is helpful to categorize your production code into four categories along two dimensions: thinking, and talking.</p>

<ul>
  <li><em>Thinking code.</em> There are parts of your codebase that are focused mostly on the business logic and the complex algorithmic computations. I refer to these as the thinking code.</li>
  <li><em>Talking code.</em> There are parts of your codebase that are focused mostly on communicating with other dependencies such as key-value stores, log servers, databases, etc. I refer to these as talking code.</li>
</ul>

<p>Each part of your codebase can be either thinking, talking, or both. Based on that observation, we can categorize each unit of code into one of four categories (in keeping with the biology theme).</p>

<table>
  <thead>
    <tr>
      <th>Thinking</th>
      <th>Talking</th>
      <th>Category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Yes</td>
      <td>No</td>
      <td><em>Brain</em></td>
    </tr>
    <tr>
      <td>No</td>
      <td>Yes</td>
      <td><em>Nerves</em></td>
    </tr>
    <tr>
      <td>Yes</td>
      <td>Yes</td>
      <td><em>Ganglia</em></td>
    </tr>
    <tr>
      <td>No</td>
      <td>No</td>
      <td><em>Synapse</em></td>
    </tr>
  </tbody>
</table>

<h2 id="testing-for-each-category">Testing for each category</h2>

<p>Each category needs a distinct approach to testing.</p>

<h3 id="brains--unit-tests">Brains → Unit Tests</h3>

<p>Brains are one of the most complex parts of your codebase that often requires the most technical skill and domain knowledge to author, read, and maintain. Consequently, they are best tested with unit tests. Furthermore, they also have very few direct external dependencies, and as a result require limited use of test doubles.</p>

<h3 id="nerves--integration-tests">Nerves → Integration Tests</h3>

<p>Nerves have very little logic, but focus mostly on external communication with dependencies.
As a result, there isn’t much to unit test here, except perhaps that the protocol translation from the outside world into the brains is happening correctly.
By their very nature, the correctness of nerves cannot be tested hermetically, and therefore, are not at all well suited to be unit tested. Nerves should really be tested in your integration tests, where you hook your production code with real test instances of external dependencies.</p>

<h3 id="ganglia--refactor">Ganglia → Refactor</h3>

<p>Ganglia are units of code that have both complex business logic and have significant external dependencies. It is very difficult to unit test them thoroughly because such unit tests require heavy use of test doubles which can make the tests less readable and more brittle. You could try to test ganglia through integration tests, but it becomes very challenging to test low probability code paths, which is usually the source of difficult-to-debug issues. Therefore, my suggestion is to refactor such code into smaller pieces of code each of which are either a <em>brain</em> or a <em>nerve</em>, and tests each of those as described above.</p>

<p>See Chapter 7 of “<a href="https://www.manning.com/books/unit-testing">Unit Testing: Principles, Practices, and Patterns</a>” for suggestions on how to refactor your code to make it more testable.</p>

<h3 id="synapse--ignore">Synapse → Ignore</h3>

<p>Synapses are trivial pieces of code (often utilities) that have neither complex business logic, nor do they have any external dependencies. My recommendation is to simply not focus on testing them. Adding unit tests for them simply increases the cost of testing and maintenance without really providing any benefit. They are often simple enough to be verified visually, and they exist only to serve either the brains or the nerves, and so will be indirectly tested via unit tests or integration tests.</p>]]></content><author><name>Srikanth Sastry</name><email>srikanth@sastry.name</email></author><category term="professional" /><category term="testing" /><category term="software engineering" /><category term="integration tests" /><category term="unit tests" /><summary type="html"><![CDATA[Unit tests are typically your first line of defense against bugs. So, it is tempting to add unit tests for all functionality that your code supports. But that begs the following question. "Why do we need integration and end-to-end tests?" Unit tests most benefit the most complex parts of your codebase that often requires the most technical skill and domain knowledge to author, read, and maintain. Integration tests disproportionately benefit the parts of your codebase that communicate with external dependencies.]]></summary></entry><entry><title type="html">Mocks, Stubs, and how to use them</title><link href="//srikanth.sastry.name/mocks-stubs-andhow-to-use-them/" rel="alternate" type="text/html" title="Mocks, Stubs, and how to use them" /><published>2022-05-25T00:00:00+00:00</published><updated>2022-05-25T00:00:00+00:00</updated><id>//srikanth.sastry.name/mocks-stubs-and-how-to-use-them</id><content type="html" xml:base="//srikanth.sastry.name/mocks-stubs-andhow-to-use-them/"><![CDATA[<p><img src="/images/masquerade-masks.png" alt="Photo by Polina Kovaleva from Pexels" />
<em>Photo by <a href="https://www.pexels.com/@polina-kovaleva?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Polina Kovaleva</a> from <a href="https://www.pexels.com/photo/close-up-of-masquerade-masks-on-purple-background-8404608/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Pexels</a></em></p>

<p><a href="https://en.wikipedia.org/wiki/Test_double">Test doubles</a> are the standard mechanism to isolate your System-Under-Test (SUT) from external dependencies in unit tests. Unsurprisingly, it is important to use the right test double for each use case for a maintainable and robust test suite. However, I have seen a lot of misuse of test doubles, and suffered through the consequences of it enough number of times to want to write down some (admittedly subjective) guidelines on when an how to use test doubles.</p>

<p>Briefly, test doubles are <a href="https://martinfowler.com/bliki/TestDouble.html">replacements for a production object used for testing</a>. Depending on who you ask, there are multiple different categorizations of test doubles; but two categories that appears in all of these categorizations are <a href="https://en.wikipedia.org/wiki/Mock_object">mocks</a> and <a href="https://en.wikipedia.org/wiki/Test_stub">stubs</a>. So I will focus on on these two. I have seen mocks and stubs often conflated together. The problem is made worse by all the test-double frameworks’ terminology: they are often referred to as ‘mocking’ frameworks, and the test doubles they generate are all called ‘mocks’.</p>

<h2 id="mocks">Mocks</h2>

<p><img src="/images/woman-wearing-emoji-mask.jpg" alt="woman wearing an emoji mask" /></p>

<p><em>Image by <a href="https://pixabay.com/users/5697702-5697702/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2428737">Andii Samperio</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2428737">Pixabay</a></em></p>

<p>Mocks are objects that are used to verify ‘outbound’ interactions of the SUT with external dependencies. This is different from the notion of ‘mocks’ that ‘mocking frameworks’ generate. Those ‘mocks’ are more correctly the superclass of test doubles.
Examples where mocks are useful include the SUT logging to a log server, or sending an email, or filing a task/ticket in response to a given input/user journey. This becomes clearer with an illustration.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">MagicMock</span>

<span class="k">class</span> <span class="nc">TestSUT</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">test_log_success</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">mock_log_server</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">LogServerClass</span><span class="p">,</span> <span class="n">autospec</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">mock_log_server</span><span class="p">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">(</span><span class="n">return_value</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">sut</span> <span class="o">=</span> <span class="n">SUT</span><span class="p">(</span><span class="n">log_server</span><span class="o">=</span><span class="n">mock_log_server</span><span class="p">)</span>
        
        <span class="n">sut</span><span class="p">.</span><span class="n">test_method</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s">"foo"</span><span class="p">)</span>
        
        <span class="c1"># This is ok!
</span>        <span class="n">mock_log_server</span><span class="p">.</span><span class="n">log</span><span class="p">.</span><span class="n">assert_called_once_with</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s">"foo"</span><span class="p">)</span>

</code></pre></div></div>

<p>Note that in the above illustration, we verify that the message is sent to the the log server exactly once. This is an important part of the SUT’s specification. It the SUT were to start logging multiple messages/records for the request, then it could pollute the logs or even overwhelm the log server. Here, even though logging appears to be a side effect of <code class="language-plaintext highlighter-rouge">test_method</code>, this side effect is almost certainly part of SUT’s specification, and needs to be verified correctly. Mocks play a central role in such verifications.</p>

<h2 id="stubs">Stubs</h2>

<p><img src="/images/robot-imitating-family.jpg" alt="Robot imitating family" /></p>

<p>Unlike mocks, stubs verify ‘inbound’ interactions from external dependencies to the SUT. Stubs are useful when replacing external dependencies that ‘send’ data to the SUT in order for the SUT to satisfy its specification. Examples include key value stores, databases, event listeners, etc. The important note here is that the outbound interaction to the stub <em>should not be asserted</em> in the tests; that’s an anti pattern (it results in over-specification)! Here is an illustration.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">MagicMock</span>

<span class="k">class</span> <span class="nc">TestSUT</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">test_email_retrieval</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">stub_key_value_store</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">KeyValueStoreClass</span><span class="p">,</span> <span class="n">autospec</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">stub_key_value_store</span><span class="p">.</span><span class="n">get</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">(</span><span class="n">return_value</span><span class="o">=</span><span class="s">"user@special_domain.com"</span><span class="p">)</span>
        <span class="n">sut</span> <span class="o">=</span> <span class="n">SUT</span><span class="p">(</span><span class="n">key_value_store</span><span class="o">=</span><span class="n">stub_key_value_store</span><span class="p">)</span>
        
        <span class="n">email_domain</span> <span class="o">=</span> <span class="n">sut</span><span class="p">.</span><span class="n">get_user_email_domin</span><span class="p">(</span><span class="n">username</span><span class="o">=</span><span class="s">"foo"</span><span class="p">)</span>
        
        <span class="c1"># This is ok!
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="s">"special_domain.com"</span><span class="p">,</span> <span class="n">email_domain</span><span class="p">)</span>
        
        <span class="c1"># THIS IS NOT OK!
</span>        <span class="n">stub_key_value_store</span><span class="p">.</span><span class="n">get</span><span class="p">.</span><span class="n">assert_called_once_with</span><span class="p">(</span><span class="n">username</span><span class="o">=</span><span class="s">"foo"</span><span class="p">)</span>

</code></pre></div></div>
<p>In the above illustration, we create a stub for the key value store (note that this is a stub even thought the object is a ‘mock’ class) that returns <code class="language-plaintext highlighter-rouge">"user@special_domain.com"</code> as a canned response to a <code class="language-plaintext highlighter-rouge">get</code> call. The test verifies that the SUT’s <code class="language-plaintext highlighter-rouge">get_user_email_domain</code> is called, it returns the correct email domain. What is important here is that we <em>should not</em> assert that there was a <code class="language-plaintext highlighter-rouge">get</code> call to the stub. Why? Because the call to the key value store is an implementation detail. Imagine a refactor that causes a previous value to be cached locally. If the unit tests were to assert on calls to the stubs, then such refactors would result in unit test failures, which undermines the utility, maintainability, and robustness of unit tests.</p>

<h3 id="fakes-instead-of-stubs">Fakes, instead of stubs</h3>

<p>A small detour here. When using a stub, always consider if you can use a fake instead. There are multiple definitions of a fake, and the one I am referring to is the following. A fake is a special kind of stub that implements the same API as the production dependency, but the implementation is much more lightweight. This implementation may be correct only within the context of the unit tests where it is used. Let’s reuse the previous illustration of using a stub, and replace the stub with a fake. Recall that we stubbed out the <code class="language-plaintext highlighter-rouge">get</code> method of <code class="language-plaintext highlighter-rouge">KeyValueStoreClass</code> to return the canned value <code class="language-plaintext highlighter-rouge">"user@special_domain.com"</code>. Instead, we can implement a fake <code class="language-plaintext highlighter-rouge">KeyValueStoreClass</code> that uses a <code class="language-plaintext highlighter-rouge">Dict</code> as follows.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">MagicMock</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="c1"># We assume a simplistic API for KeyValueStoreClass with just
# update and get methods.
</span><span class="k">class</span> <span class="nc">KeyValueStoreClass</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>
    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="p">...</span>

<span class="k">class</span> <span class="nc">FakeKeyValueStoreClassImpl</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">kvs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">kvs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">kvs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">TestSUT</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">test_email_retrieval</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">FakeKeyValueStoreClass</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">(</span><span class="n">return_value</span><span class="o">=</span><span class="n">FakeKeyValueStoreClassImpl</span><span class="p">())</span>
        <span class="n">fake_key_value_store</span> <span class="o">=</span> <span class="n">FakeKeyValueStoreClass</span><span class="p">()</span>
        <span class="n">fake_key_value_store</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="s">"foo"</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="s">"user@special_domain.com"</span><span class="p">)</span>
        <span class="n">sut</span> <span class="o">=</span> <span class="n">SUT</span><span class="p">(</span><span class="n">key_value_store</span><span class="o">=</span><span class="n">fake_key_value_store</span><span class="p">)</span>
        
        <span class="n">email_domain</span> <span class="o">=</span> <span class="n">sut</span><span class="p">.</span><span class="n">get_user_email_domin</span><span class="p">(</span><span class="n">username</span><span class="o">=</span><span class="s">"foo"</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="s">"special_domain.com"</span><span class="p">,</span> <span class="n">email_domain</span><span class="p">)</span>
</code></pre></div></div>

<p>The advantage of using a fake is that the test becomes much more robust and is more resistant to refactoring. It also becomes more extensible. When using a stub, if we wanted to test a different user journey, we would need to inject a new return value for <code class="language-plaintext highlighter-rouge">KeyValueStoreClass.get</code> method. We would in one of two ways:  (1) resetting the mock, which is a bad anti-pattern, or (2) initialize the stub to return a preconfigured list of canned values, in order, which makes the test more brittle (consider what happens if the SUT chooses to call <code class="language-plaintext highlighter-rouge">get</code> for the same key twice vs. calls <code class="language-plaintext highlighter-rouge">get</code> for different keys once each). Using a fake sidesteps these issues.</p>

<h2 id="but-my-dependency-has-both-inbound-and-outbound-interactions">But my dependency has both inbound and outbound interactions!</h2>

<p><img src="/images/man-double-exposed-photo.jpg" alt="Photograph of man double exposure" /></p>

<p>Despite all your efforts to separate out the test cases that need stubs and the ones that need mocks, you will inevitably find yourself needing to test a scenario in which you need to verify both inbound and outbound interactions with an external dependency. How do we address that?</p>

<p>First, if you need to assert on the outbound interaction of the same call that is stubbed, then you really don’t need that test. Just use a stub/fake and do not assert on the outbound interaction. Next, the only legitimate case of needing to verify both inbound and outbound interactions is if they are on distinct APIs of the same dependency. For example, the SUT could be reading from a file, and you need to test that (1) the contents of the file were read correctly, and (2) the file object was closed after the file was read. In this case, it is perfectly ok to stub the file <code class="language-plaintext highlighter-rouge">read</code> method while mocking the <code class="language-plaintext highlighter-rouge">close</code> method. Here is an illustration.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">MagicMock</span><span class="p">,</span> <span class="n">patch</span>

<span class="k">class</span> <span class="nc">TestSUT</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">test_file_read</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">file_mock_stub_combo</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">()</span>
        <span class="c1"># Using this as a stub by injecting canned contents of the file
</span>        <span class="n">file_mock_stub_combo</span><span class="p">.</span><span class="n">__iter__</span><span class="p">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="p">[</span><span class="s">"1234"</span><span class="p">]</span>
        
        <span class="c1"># Next, we treat the file open call as a mock.
</span>        <span class="k">with</span> <span class="n">patch</span><span class="p">(</span><span class="s">"builtins.open"</span><span class="p">,</span>
                   <span class="n">return_value</span><span class="o">=</span><span class="n">file_mock_stub_combo</span><span class="p">,</span> 
                   <span class="n">create</span><span class="o">=</span><span class="bp">True</span>
                  <span class="p">)</span> <span class="k">as</span> <span class="n">mock_file</span><span class="p">:</span>
            <span class="n">sut</span> <span class="o">=</span> <span class="n">SUT</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s">"foo"</span><span class="p">)</span>
            <span class="n">file_contents</span> <span class="o">=</span> <span class="n">sut</span><span class="p">.</span><span class="n">get_contents</span><span class="p">()</span>
            
            <span class="c1"># Assertions on call to file open.
</span>            <span class="c1"># Treating the 'open' call as a mock.
</span>            <span class="n">mock_file</span><span class="p">.</span><span class="n">assert_called_once_with</span><span class="p">(</span><span class="s">"foo"</span><span class="p">)</span>
        
            <span class="c1"># Assertion on the contents returned.
</span>            <span class="c1"># Treating the `read` as a stub.
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="s">"1234"</span><span class="p">,</span> <span class="n">file_contents</span><span class="p">)</span>
        
            <span class="c1"># Assertion on the outbound interaction of file close.
</span>            <span class="c1"># Treating the 'close' call as a mock.
</span>            <span class="n">file_mock_stub_combo</span><span class="p">.</span><span class="n">close</span><span class="p">.</span><span class="n">assert_called_once</span><span class="p">()</span>
</code></pre></div></div>]]></content><author><name>Srikanth Sastry</name><email>srikanth@sastry.name</email></author><category term="Professional" /><category term="testing" /><category term="software engineering" /><category term="test doubles" /><category term="unit tests" /><category term="mocks" /><category term="stubs" /><summary type="html"><![CDATA[Test doubles are the standard mechanism to isolate your System-Under-Test (SUT) from external dependencies in unit tests. Unsurprisingly, it is important to use the right test double for each use case for a maintainable and robust test suite. However, I have seen a lot of misuse of test doubles, and suffered through the consequences of it enough number of times to want to write down some (admittedly subjective) guidelines on when an how to use test doubles.]]></summary></entry><entry><title type="html">DRY unit tests are bad… mkay</title><link href="//srikanth.sastry.name/dry-unit-tests-are-bad/" rel="alternate" type="text/html" title="DRY unit tests are bad… mkay" /><published>2022-05-17T00:00:00+00:00</published><updated>2022-05-17T00:00:00+00:00</updated><id>//srikanth.sastry.name/DRY-unit-tests-are-bad</id><content type="html" xml:base="//srikanth.sastry.name/dry-unit-tests-are-bad/"><![CDATA[<p><img src="/images/squeeze-cloth.jpg" alt="DRY" /></p>

<p><a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">“Don’t Repeat Yourself” (DRY)</a> is arguably one of the most important principles in software engineering. It is considered a truism among many. A consequence of such dogmatic allegiance to DRYness is that we see a lot of DRY unit tests; this is where the utility of the DRY principle breaks downs and starts causing more problems that it solves.</p>

<p><strong>TL;DR.</strong> <em>Simplicity</em> should be a core property of unit tests. This is motivated, both by arguments in this post against DRY unit tests, and by <a href="https://srikanth.sastry.name/the-big-why-about-unit-tests/">software maintainability as the primary motivation for unit tests</a>. Unit tests should be as simple as reasonable. It should be easy to ready, understand, and modify (it should be easy to modify any single test in isolation). It is perfectly acceptable for this simplicity to come at the expense of code-reuse, performance, and efficiency.</p>

<h2 id="so-whats-wrong-with-dry-unit-tests">So, what’s wrong with DRY Unit Tests?</h2>
<p>Presumably, we are all convinced of the benefits of DRYing your code (interested readers can go <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">the Wikipedia page</a>). It does have some downsides, and so you have the notion of the <a href="http://blog.jayfields.com/2006/05/dry-code-damp-dsls.html">DAMP</a>/<a href="https://startup-cto.net/moist-code-why-code-should-not-be-completely-dry/">MOIST</a>/<a href="https://kentcdodds.com/blog/aha-programming">AHA</a> principle. Interestingly, the reasons why DRYness doesn’t always work out in production code are different from why it is a bad idea to write DRY unit tests. I see five ways in which (a) test code is different from production code and (b) it contributes to why test code should not be DRY.</p>

<ol>
  <li>Tests (conceptually) do not yield well to common abstractions.</li>
  <li>Test code’s readability always takes precedence over performance, but not so for production code.</li>
  <li>Production code enjoys the safety net of test code, but test code has no such backstop.</li>
  <li>DRY production code can speed up developer velocity, but DRY test code hinders developer velocity.</li>
  <li>Complex changes to production code can be reviewed faster with pure green/pure red test code changes, but complex changes to test code cannot be reviewed easily.</li>
</ol>

<p>Let’s explore each one in more detail.</p>

<h3 id="dryness-and-abstraction">DRYness and Abstraction</h3>
<p><img src="/images/triangles-abstract.png" alt="Abstract" />
In practice, DRYing out code results in building abstractions that <em>represents a collection of semantically identical operations</em> into common procedure. If done prematurely, then DRYing can result in poorer software. In fact, premature DRYing is the motivation for advocating the <a href="https://kentcdodds.com/blog/aha-programming">AHA</a> principle. While that argument against DRYness works well in production code, it does not apply for test code.</p>

<p>Test code is often a collection of procedures, and each procedure steps the System-Under-Test (SUT) through a distinct user journey and compares the SUT’s behavior against pre-defined expectations. Thus, almost by design, test code does not yield itself semantically similar abstractions. The mistake that I have seen software engineers make is to mistake syntactic similarly for semantic similarity. Just because the tests’ ‘Arrange’ sections look similar does not mean that they are doing semantically the same thing in both places; in fact, they are almost certainly doing semantically different things because otherwise, the tests are duplicates of each other!</p>

<p>By DRYing out such test code, you are effectively forcing abstractions where none exist, and that leads to the same issues that DRYness leads to in production code (See <a href="https://kentcdodds.com/blog/aha-programming">[1]</a>, <a href="https://sandimetz.com/blog/2016/1/20/the-wrong-abstraction">[2]</a>, <a href="https://evhaus.medium.com/using-dry-wet-damp-code-6ab3c8245bb2">[3]</a>, <a href="https://startup-cto.net/moist-code-why-code-should-not-be-completely-dry/">[4]</a> for examples).</p>

<h3 id="readability">Readability</h3>
<p><img src="/images/glasses-letters-clear.jpg" alt="Abstract" />
Most code is read more often than is written/edited. Unsurprisingly, it is important to favor code readability, even in production code. However, in production code, if this comes at a steep cost in performance and/or efficiency, then it is common (and prudent) to favor performance over readability. Test code, on the other hand, is less subject to the (potential) tension between readability and performance. Yes, unit tests need to be ‘fast’, but given the minuscule amount of data/inputs that unit tests process, speed is not an issue with hermetic unit tests. The upshot here is that there is no practical drawback to keeping test code readable.</p>

<p>DRYing out test code directly affects its readability. Why? Remember that we read unit tests to understand the expected behavior of the system-under-test (SUT), and we do so in the context of a user journey. So, a readable unit test needs to explain the user journey it is executing, the role played by the SUT in realizing that user journey, and what a successful user journey looks like. This is reflected in the <a href="https://java-design-patterns.com/patterns/arrange-act-assert/">Arrange-Act-Assert</a> structure of the unit test. When you DRY out your unit tests, you are also obfuscating at least one of those sections in your unit test. This is better illustrated with an example.</p>

<p>A common DRYing in unit tests I have seen looks as follows:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TestInput</span><span class="p">(</span><span class="n">typing</span><span class="p">.</span><span class="n">NamedTuple</span><span class="p">):</span>
    <span class="n">param1</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">param2</span><span class="p">:</span> <span class="n">typing</span><span class="p">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="p">...</span>

<span class="k">class</span> <span class="nc">TestOutput</span><span class="p">(</span><span class="n">typing</span><span class="p">.</span><span class="n">NamedTuple</span><span class="p">):</span>
    <span class="n">status</span><span class="p">:</span> <span class="n">SomeEnum</span>
    <span class="n">return_value</span><span class="p">:</span> <span class="n">typing</span><span class="p">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="n">exception</span><span class="p">:</span> <span class="n">typing</span><span class="p">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">Exception</span><span class="p">]</span>
    <span class="p">...</span>

<span class="k">class</span> <span class="nc">TestCase</span><span class="p">(</span><span class="n">typing</span><span class="p">.</span><span class="n">NamedTuple</span><span class="p">):</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">TestInput</span>
    <span class="n">expected_output</span><span class="p">:</span> <span class="n">TestOutput</span>
        
<span class="k">class</span> <span class="nc">TestSequence</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    
    <span class="o">@</span><span class="n">parameterized</span><span class="p">.</span><span class="n">expand</span><span class="p">([</span>
        <span class="p">[</span><span class="n">test_input1</span><span class="p">,</span> <span class="n">expected_output1</span><span class="p">],</span>
        <span class="p">[</span><span class="n">test_input2</span><span class="p">,</span> <span class="n">expected_output2</span><span class="p">],</span>
        <span class="p">...</span>
    <span class="p">])</span>
    <span class="k">def</span> <span class="nf">test_somethings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_input</span><span class="p">:</span> <span class="n">TestInput</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">:</span> <span class="n">TestOutput</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_run_test</span><span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">_run_test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_input</span><span class="p">:</span> <span class="n">TestInput</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">:</span> <span class="n">TestOutput</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">sut</span> <span class="o">=</span> <span class="n">SUT</span><span class="p">(...)</span>
        <span class="n">prepare_sut_for_tests</span><span class="p">(</span><span class="n">sut</span><span class="p">,</span> <span class="n">test_input</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">sut</span><span class="p">.</span><span class="n">do_something</span><span class="p">(</span><span class="n">test_input</span><span class="p">.</span><span class="n">param2</span><span class="p">)</span>
        <span class="n">test_output</span> <span class="o">=</span> <span class="n">make_test_output</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">sut</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">test_output</span><span class="p">)</span>
</code></pre></div></div>
<p>On the face of it, it looks like DRY organized code. But for someone reading this test to understand what SUT does, it is very challenging. They have no idea why the set of <code class="language-plaintext highlighter-rouge">test_input</code>s were chosen, what is the material difference among the inputs, what user journeys do each of those test cases represent, what are the preconditions that need to be satisfied for running <code class="language-plaintext highlighter-rouge">sut.do_something()</code>, why is the expected output the specified output, and so on.</p>

<p>Instead, consider a non-DRY alternative.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TestSequence</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">test_foo_input_under_bar_condition</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""
        This test verifies that when condition bar is true, then calling `do_something()`
        with input foo results in sigma behavior
        """</span>
        <span class="n">sut</span> <span class="o">=</span> <span class="n">SUT</span><span class="p">()</span>
        <span class="n">ensure_precondition_bar</span><span class="p">(</span><span class="n">sut</span><span class="p">,</span> <span class="n">param1</span><span class="o">=</span><span class="n">bar1</span><span class="p">,</span> <span class="n">param2</span><span class="o">=</span><span class="n">bar2</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">sut</span><span class="p">.</span><span class="n">do_something</span><span class="p">(</span><span class="n">foo</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</code></pre></div></div>
<p>This code tests one user journey and is human readable at a glance by something who does not have in-depth understanding of SUT. We can similarly define all the other test cases with code duplication and greater readability, with negligible negative impact.</p>

<h3 id="who-watches-the-watchmen">Who watches the watchmen?</h3>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Watchmen_graffiti_1.jpg/2560px-Watchmen_graffiti_1.jpg" alt="colink., CC BY-SA 2.0 &lt;https://creativecommons.org/licenses/by-sa/2.0&amp;gt" />
<em>[<a href="https://www.flickr.com/photos/67458569@N00/7099293919">Original Image</a> posted to <a href="https://en.wikipedia.org/wiki/Flickr" title="en:Flickr">Flickr</a> by colink. License: <a href="https://creativecommons.org/licenses/by-sa/2.0/">Creative Commons ShareAlike</a>]</em></p>

<p>Production code has the luxury of being fine tuned, optimized, DRY’d out, and subject to all sorts of gymnastics mostly because production code is defended by tests and test code. For instance, to improve performance, if you replaced a copy with a reference, and accidentally mutated that reference inside a function, you have a unit test that can catch such unintended mutations. However, test code has no such backstop. If you introduce a bug in your test code, then only a careful inspection by a human will catch it. The upshot is the following: the less simple/obvious the test code is, the more likely it is that a bug in that test code will go undetected, at least for a while. If a buggy test is passing, then it means your production code has a bug that is undetected. Conversely, if a test fails then, it might just denote a bug in the test code. If this happens, you lose confidence in your test suite, and nothing good can come from that.</p>

<p>DRY code inevitably asks the reader to jump from one function to another and requires the reader to keep the previous context when navigating these functions. In other words, it increases the cognitive burden on the reader compared to straight line duplicated code. That makes it difficult to verify the correctness of the test code quickly and easily. So, when you DRY out your test code, you are increasing the odds that bugs creep into your test suite, and developers lose confidence in the tests, which in turn significantly reduces the utility if your tests.</p>

<h3 id="developer-velocity">Developer Velocity</h3>
<p><img src="/images/woman-developer-frustrated.jpg" alt="Woman developer" /></p>

<p>Recall from the previous section that while tests might have duplicate code, they do not actually represent semantic abstractions replicated in multiple places. If you do mistake them for common semantic abstractions and DRY them out, then eventually there will an addition to the production code whose test breaks this semantic abstraction. At this point, the developer who is adding this feature will run into issues when trying to modify the existing test code to add the new test case. For instance, consider a class that is hermetic, stateless, and does not throw exceptions. It would not be surprising to organize DRY tests for this class that assumes that exceptions are never thrown. Now there is a new feature added to this class that requires an external dependency, and now can throw exceptions. Added a new test case into the DRY’d out unit test suite will not be easy or straightforward. The sunk cost fallacy associated with the existing test framework makes it more likely that the developer will try to force-fit the new test case(s) into existing framework. As a result:</p>

<ol>
  <li>It slows the developer down because they now have to grok the existing test framework, think of ways in which to extend it for a use case that it was not designed for, and make those changes without breaking existing tests.</li>
  <li>Thanks to poor abstractions, you have now incurred more technical debt in your test code.</li>
</ol>

<h3 id="code-reviews">Code Reviews</h3>
<p><img src="/images/black-women-developers.jpg" alt="Developers doing code reviews" /></p>

<p>DRY’d out tests not only impede developer velocity, they also make it less easy to review code/diffs/pull requests. This is a second order effect of DRYing out your test code. Let’s revisit the example where we are adding a new feature to an existing piece of code, and this is a pure addition in behavior (not modification to existing behavior). If the tests were not DRY’d out, then adding tests for this new feature would involve just adding new test cases, and thus, just green lines in the generated diff. In contrast, recall from the previous subsection that adding tests with DRY test code is likely going to involve modifying existing code and then adding new test cases. In the former case, reviewing the tests is much easier, and as a result, reviewing that the new feature is behaving correctly is also that much easier. Reviewing the diff in the latter case is cognitively more taxing because not only does the reviewer need to verify that the new feature is implemented correctly, they also have to verify that the changes to the test code is also correct, and is not introducing new holes for bugs to escape testing. This can significantly slow down code reviews in two ways (1) it requires more time to review the code, and (2) because it requires longer to review the code, the reviewers are more likely to delay even starting the code review.</p>]]></content><author><name>Srikanth Sastry</name><email>srikanth@sastry.name</email></author><category term="Professional" /><category term="testing" /><category term="software engineering" /><category term="unit tests" /><summary type="html"><![CDATA[Simplicity should be a core property of unit tests. This is motivated, both by arguments in this post against DRY unit tests, and by software maintainability as the primary motivation for unit tests. Unit tests should be as simple as reasonable. It should be easy to ready, understand, and modify (it should be easy to modify any single test in isolation). It is perfectly acceptable for this simplicity to come at the expense of code-reuse, performance, and efficiency.]]></summary></entry><entry><title type="html">Do not index on test coverage metrics</title><link href="//srikanth.sastry.name/do-not-index-in-test-coverage/" rel="alternate" type="text/html" title="Do not index on test coverage metrics" /><published>2022-04-29T00:00:00+00:00</published><updated>2022-04-29T00:00:00+00:00</updated><id>//srikanth.sastry.name/do-not-index-on-test-coverage</id><content type="html" xml:base="//srikanth.sastry.name/do-not-index-in-test-coverage/"><![CDATA[<p><img src="/images/chart-coverage.png" alt="Coverage Chart" /></p>

<p>We live in a data driven world, and as the saying goes “[…] What is not measured, cannot be improved. […]”</p>
<blockquote>
  <p>What is not defined cannot be measured. What is not measured, cannot be improved. What is not improved, is always degraded.</p>

  <p>– William Thomson Kelvin</p>
</blockquote>

<p>The temptation, therefore, is to measure everything. Even the quality of your unit tests, and there where the trouble usually begins. For an detailed explanation of why indexing on the test coverage metrics is a bad idea, I highly recommend Jason Rudolph’s collection of posts on this topic <a href="https://jasonrudolph.com/blog/testing-anti-patterns-how-to-fail-with-100-test-coverage/">here</a>. To drive home the point more explicitly (and motivate you to actually go read Jason’s posts), here are some illustrative explanations.</p>

<p>There are many coverage metrics including function coverage, statement coverage, line coverage, branch coverage, condition coverage, etc. Here, we will only look at line coverage and branch coverage, because those are the most popular.</p>

<h2 id="line-coverage">Line coverage</h2>
<p>Let’s start with <em>line coverage</em>, which is the number of lines of code executed by tests vs. the total number of lines of code. The most common target for the line coverage metric is 80%. That is, 80% of your code should be executed by your tests. While that might seem like a good idea, indexing on this metric can actually take you away from good quality test coverage! How? Consider the following (contrived example).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">has_three_digits</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="n">strlen</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">strlen</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">True</span>
    <span class="k">return</span> <span class="bp">False</span>

<span class="k">class</span> <span class="nc">TestHasThreeDigits</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">test_has_three_digits_234</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">output_value</span> <span class="o">=</span> <span class="n">has_three_digits</span><span class="p">(</span><span class="mi">234</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">assertTrue</span><span class="p">(</span><span class="n">output_value</span><span class="p">)</span>
</code></pre></div></div>
<p>Clearly <code class="language-plaintext highlighter-rouge">TestHasThreeDigits</code> inadequate as a test suite for testing <code class="language-plaintext highlighter-rouge">has_three_digits</code>. Tests only the True case, and misses the False cases completely!
The line coverage of the test suite is 3/4 = 75%. You could say that the test coverage is less than 80%, and therefore not adequate. Here, it appears that the line coverage metric does indeed point of inadequate testing. However, this confidence in the metric is severely misplaced! Consider the following refactoring of <code class="language-plaintext highlighter-rouge">has_three_digits</code></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">has_three_digits</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="n">value_as_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="n">strlen</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_as_str</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">strlen</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">True</span>
    <span class="k">return</span> <span class="bp">False</span>
</code></pre></div></div>
<p>Now, <code class="language-plaintext highlighter-rouge">TestHasThreeDigits</code> line coverage magically improves to 4/5 = 80%, and as per the 80% target, the metrics seems to suggest adequate coverage! In fact, you can play this game some more and refactor <code class="language-plaintext highlighter-rouge">has_three_digits</code> to</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">has_three_digits</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="n">value_as_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="n">strlen</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_as_str</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">strlen</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>
<p>Now, with the same test suite <code class="language-plaintext highlighter-rouge">TestHasThreeDigits</code> now has 100% coverage! Recall that semantically the test still do the same thing; they still test only the True case, and ignore the False case completely.</p>

<h2 id="branch-coverage">Branch coverage</h2>
<p>An easy retort to the above example is that line coverage is not a sufficiently nuanced metric, and what you really need is <em>branch coverage</em>, which is the number of branches executed by the tests vs. the number of branches in the code.</p>

<p>Looking at the branch coverage of <code class="language-plaintext highlighter-rouge">TestHasThreeDigits</code>, we can see that it has a 50% branch coverage, which is inadequate. Well, here’s an easy way to improve that.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TestHasThreeDigits</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">test_has_three_digits_true</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">true_output_value</span> <span class="o">=</span> <span class="n">has_three_digits</span><span class="p">(</span><span class="mi">234</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_has_three_digits_false</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">false_output_value</span> <span class="o">=</span> <span class="n">has_three_digits</span><span class="p">(</span><span class="mi">23</span><span class="p">)</span>
</code></pre></div></div>
<p>See, now the test suite has 100% branch coverage! However, not that it has no assertions at all. So, despite having 100% line and branch coverage, this test suite is completely useless! (This is a form of <a href="https://jasonrudolph.com/blog/2008/06/17/testing-anti-patterns-incidental-coverage/">incidental coverage anti-pattern</a>.)</p>

<p>Here is a more nuanced example:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">HasThreeDigits</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        
    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span>
    
<span class="k">class</span> <span class="nc">TestHasThreeDigits</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">test_has_three_digits_234</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">output_value</span> <span class="o">=</span> <span class="n">has_three_digits</span><span class="p">(</span><span class="mi">234</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">assertTrue</span><span class="p">(</span><span class="n">output_value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_has_three_digits_23</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">output_value</span> <span class="o">=</span> <span class="n">has_three_digits</span><span class="p">(</span><span class="mi">23</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">output_value</span><span class="p">)</span>
</code></pre></div></div>
<p>The code coverage is 100%, branch coverage is 100%. But <code class="language-plaintext highlighter-rouge">self.counter</code> is never verified!</p>
<h2 id="wait-theres-more">Wait, there’s more!</h2>
<p>Coverage metrics only consider the code the are under your project, and ignore all external libraries. However, your code is correct only if you are satisfying the preconditions of your external library calls, and test coverage metrics do not capture any of that. Here is an illustration with an contrived example.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">external.lib</span> <span class="kn">import</span> <span class="n">convert_to_num</span>

<span class="k">def</span> <span class="nf">has_three_digits</span><span class="p">(</span><span class="n">value</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">convert_to_num</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">v</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mi">1000</span> <span class="ow">and</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="mi">1000</span>
</code></pre></div></div>
<p>The above code is expected return True if <code class="language-plaintext highlighter-rouge">value</code> is and integer with 3 digits. Here is test suite.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TestHasThreeDigits</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">test_has_three_digits_234</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">output_value</span> <span class="o">=</span> <span class="n">has_three_digits</span><span class="p">(</span><span class="s">'234'</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">assertTrue</span><span class="p">(</span><span class="n">output_value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_has_three_digits_23</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">output_value</span> <span class="o">=</span> <span class="n">has_three_digits</span><span class="p">(</span><span class="s">'23'</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">output_value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_has_three_digits_minus_23</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">output_value</span> <span class="o">=</span> <span class="n">has_three_digits</span><span class="p">(</span><span class="s">'-23'</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">output_value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_has_three_digits_minus_234</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">output_value</span> <span class="o">=</span> <span class="n">has_three_digits</span><span class="p">(</span><span class="s">'-234'</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">assertTrue</span><span class="p">(</span><span class="n">output_value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_has_three_digits_ten_times_ten</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">output_value</span> <span class="o">=</span> <span class="n">has_three_digits</span><span class="p">(</span><span class="s">'10*10'</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">assertTrue</span><span class="p">(</span><span class="n">output_value</span><span class="p">)</span>
</code></pre></div></div>
<p>The test suite looks reasonable. You line and branch coverage is a 100%, and so nothing in the metrics suggestg anything is amiss. Except that we have said nothing about how <code class="language-plaintext highlighter-rouge">convert_to_num</code> is implemented. It is easy to imagine some preconditions for the input to <code class="language-plaintext highlighter-rouge">convert_to_num</code>; for instance, it throws a ValueError exception if you pass in an input of the form <code class="language-plaintext highlighter-rouge">3/0</code>. Now, you can see how the test suite is not adequate! (<code class="language-plaintext highlighter-rouge">has_three_digits('10/0')</code> will throw an exception). But your test coverage metrics will never be able to help here.</p>]]></content><author><name>Srikanth Sastry</name><email>srikanth@sastry.name</email></author><category term="Professional" /><category term="testing" /><category term="software" /><category term="Python" /><category term="software engineering" /><summary type="html"><![CDATA[We live in a data driven world. The temptation, therefore, is to measure everything. Even the quality of your unit tests, and there where the trouble usually begins. For an detailed explanation of why indexing on the test coverage metrics is a bad idea, I highly recommend Jason Rudolph's collection of posts on this topic (https://jasonrudolph.com/blog/testing-anti-patterns-how-to-fail-with-100-test-coverage/). To drive home the point more explicitly (and motivate you to actually go read Jason's posts), here are some illustrative explanations.]]></summary></entry><entry><title type="html">Beware of using patch.object to test your Python code</title><link href="//srikanth.sastry.name/beware-of-using-patch-object-to-test-your-python-code/" rel="alternate" type="text/html" title="Beware of using patch.object to test your Python code" /><published>2022-02-28T00:00:00+00:00</published><updated>2022-02-28T00:00:00+00:00</updated><id>//srikanth.sastry.name/beware-of-using-patch-object-to-test-your-python-code</id><content type="html" xml:base="//srikanth.sastry.name/beware-of-using-patch-object-to-test-your-python-code/"><![CDATA[<p><img src="/images/software-testing.jpg" alt="Software Testing" /></p>

<p><a href="https://en.wikipedia.org/wiki/Liskov_substitution_principle">Liskov substitution principle</a> states that a class and its subclass must be interchangeable without breaking the program. Unfortunately, Python’s <a href="https://docs.python.org/3/library/unittest.mock.html#patch-object"><code class="language-plaintext highlighter-rouge">patch.object</code></a> breaks this principle in a big way. In fact, <strong>this can make your tests untrustworthy and become a maintenance headache with failures every time you extended your base class</strong>. Here is a contrived, but concrete example.</p>

<!-- more -->

<p>Say, you decide to build a special class called <code class="language-plaintext highlighter-rouge">ImmutableList</code> with a factory that looks as follows:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Sequence</span>
<span class="k">class</span> <span class="nc">ImmutableList</span><span class="p">:</span>
  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">create_list</span><span class="p">(</span><span class="nb">input</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s">"ImmutableList"</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">ImmutableList</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_inner_list</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">get_inner_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_inner_list</span>
</code></pre></div></div>

<p>Next, your system under test is a class <code class="language-plaintext highlighter-rouge">SUT</code> that uses an instance of <code class="language-plaintext highlighter-rouge">ImmutableList</code> as an injected dependency.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SUT</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wrapper</span><span class="p">:</span> <span class="n">ImmutableList</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">wrapper</span> <span class="o">=</span> <span class="n">wrapper</span>

  <span class="k">def</span> <span class="nf">get_wrapper_length</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">wrapper</span><span class="p">.</span><span class="n">get_inner_list</span><span class="p">())</span>
</code></pre></div></div>

<p>Now, when testing <code class="language-plaintext highlighter-rouge">SUT</code>, say, we patch the <code class="language-plaintext highlighter-rouge">get_inner_list()</code> method with <code class="language-plaintext highlighter-rouge">patch.object</code>:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">unittest</span> <span class="kn">import</span> <span class="n">mock</span>

<span class="k">with</span> <span class="n">mock</span><span class="p">.</span><span class="n">patch</span><span class="p">.</span><span class="nb">object</span><span class="p">(</span><span class="n">ImmutableList</span><span class="p">,</span> <span class="s">'get_inner_list'</span><span class="p">,</span> <span class="n">return_value</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="k">as</span> <span class="n">mock_method</span><span class="p">:</span>
  <span class="n">sut</span> <span class="o">=</span> <span class="n">SUT</span><span class="p">(</span><span class="n">ImmutableList</span><span class="p">.</span><span class="n">create_list</span><span class="p">([]))</span>
  <span class="k">assert</span> <span class="n">sut</span><span class="p">.</span><span class="n">get_wrapper_length</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="s">"FAILURE"</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"SUCCESS"</span><span class="p">)</span>
</code></pre></div></div>
<p>When you run this test, it does print <code class="language-plaintext highlighter-rouge">SUCCESS</code>, and therefore, works as intended.</p>

<p>Now, let’s say that we found a special case of <code class="language-plaintext highlighter-rouge">ImmutableList</code> that corresponds to a zero length list, and we implement it as follows:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ZeroLengthImmutableList</span><span class="p">(</span><span class="n">ImmutableList</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">([])</span>
  
  <span class="k">def</span> <span class="nf">get_inner_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">()</span>
</code></pre></div></div>
<p>Next, we modify the factory method to return this <code class="language-plaintext highlighter-rouge">ZeroLengthImmutableList</code>, when the input is an empty list, as follows:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">create_list</span><span class="p">(</span><span class="nb">input</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s">"ImmutableList"</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">ZeroLengthImmutableList</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ImmutableList</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></div></div>

<p>Thus, the two classes look as follows:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ImmutableList</span><span class="p">:</span>
  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">create_list</span><span class="p">(</span><span class="nb">input</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s">"ImmutableList"</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">ZeroLengthImmutableList</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ImmutableList</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_inner_list</span> <span class="o">=</span> <span class="nb">input</span>

  <span class="k">def</span> <span class="nf">get_inner_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_inner_list</span>

<span class="k">class</span> <span class="nc">ZeroLengthImmutableList</span><span class="p">(</span><span class="n">ImmutableList</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">([])</span>
  
  <span class="k">def</span> <span class="nf">get_inner_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">()</span>
</code></pre></div></div>

<p>Now, let’s go back to our test, which is still</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">unittest</span> <span class="kn">import</span> <span class="n">mock</span>

<span class="k">with</span> <span class="n">mock</span><span class="p">.</span><span class="n">patch</span><span class="p">.</span><span class="nb">object</span><span class="p">(</span><span class="n">ImmutableList</span><span class="p">,</span> <span class="s">'get_inner_list'</span><span class="p">,</span> <span class="n">return_value</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="k">as</span> <span class="n">mock_method</span><span class="p">:</span>
  <span class="n">sut</span> <span class="o">=</span> <span class="n">SUT</span><span class="p">(</span><span class="n">ImmutableList</span><span class="p">.</span><span class="n">create_list</span><span class="p">([]))</span>
  <span class="k">assert</span> <span class="n">sut</span><span class="p">.</span><span class="n">get_wrapper_length</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="s">"FAILURE"</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"SUCCESS"</span><span class="p">)</span>
</code></pre></div></div>
<p>Since <code class="language-plaintext highlighter-rouge">sut.wrapper</code> is still an <code class="language-plaintext highlighter-rouge">ImmutableList</code>, by the Liskov Substitution Principle, <code class="language-plaintext highlighter-rouge">mock.patch.object(ImmutableList, 'get_inner_list', return_value=[1, 2, 3])</code> should still return <code class="language-plaintext highlighter-rouge">[1, 2, 3]</code> when <code class="language-plaintext highlighter-rouge">sut.get_wrapper_length()</code>. However, this does not happen! The above test fails with</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AssertionError                            Traceback (most recent call last)

&lt;ipython-input-21-1c1b12b89ff3&gt; in &lt;module&gt;()
     23 with mock.patch.object(ImmutableList, 'get_inner_list', return_value=[1, 2, 3]) as mock_method:
     24   sut = SUT(ImmutableList.create_list([]))
---&gt; 25   assert sut.get_wrapper_length() == 3, "FAILURE"
     26   print("SUCCESS")

AssertionError: FAILURE
</code></pre></div></div>
<p>This forces you to change the tests every time you refactor <code class="language-plaintext highlighter-rouge">ImmutableList.create_list</code> to return a ‘better’ implementation of <code class="language-plaintext highlighter-rouge">ImmutableList</code>!</p>]]></content><author><name>Srikanth Sastry</name><email>srikanth@sastry.name</email></author><category term="Professional" /><category term="python" /><category term="patch" /><category term="testing" /><category term="software engineering" /><summary type="html"><![CDATA[Liskov substitution principle states that a class and its subclass must be interchangeable without breaking the program. Unfortunately, Python's `patch.object` breaks this principle in a big way. In fact, this can make your tests untrustworthy and become a maintenance headache with failures every time you extended your base class.]]></summary></entry><entry><title type="html">When I first realized my privilege</title><link href="//srikanth.sastry.name/when-i-first-realized-my-privilege/" rel="alternate" type="text/html" title="When I first realized my privilege" /><published>2022-02-26T00:00:00+00:00</published><updated>2022-02-26T00:00:00+00:00</updated><id>//srikanth.sastry.name/when-i-first-realized-my-privilege</id><content type="html" xml:base="//srikanth.sastry.name/when-i-first-realized-my-privilege/"><![CDATA[<p><img src="/images/handcuffed.jpg" alt="Oppressed" /></p>

<p>Ironically, a sure marker of privilege is not realizing your own privilege. I grew up being told that I am a Brahmin, which is the highest caste, and that it makes us superior and better than others. Unsurprisingly, I was taught that we were, in fact, an oppressed minority. The government reservations for the so-called Scheduled Castes and Scheduled Tribes were often cited as evidence of such oppression. So, naturally, I grew up knowing nothing about the privilege that I enjoyed.</p>

<p>For the first 23 years of my life, I was convinced that everything that came my way was hard earned, and it was despite the oppression against our community. At 23, I was working as a young software engineer in Bangalore. I needed the house deep cleaned, and a contractor said that he would send a couple of people over who would take care of it for us. I was about to get my first glimpse into the privilege that I had enjoyed all my life.</p>

<!-- more -->

<p>The two people that the contractor send over were completely clueless. They had no idea how to go about the job. They showed up empty handed and asked us what they should be using to clean the house. They required constant supervision and direction, and it consumed most of our time, and defeated the purpose of hiring them in the first place. By the end of the day, less than half the work was done, I was completely frustrated.</p>

<p>It is important to mention that these two folks’ work ethic was never in doubt. They worked as hard and diligently as you could be expected. They were from a village some hours away, quite illiterate, and desperate for work. They hadn’t seen houses in cities before, and so no idea what is involved in the upkeep of a proper house. They probably lived in shanty small houses, and this was all alien to them.</p>

<p>Coming back to the main story, it was close to evening, and very little of the work was done. At this point, the they said that they had to leave because if they didn’t leave right away, then they’d miss the last bus to their village and they’d have to walk home. So if we could pay them, then they will be on their way (and settle the account with the contractor later).</p>

<p>I was pretty upset at this point, and I told them that they hadn’t completed even half the work, and so I’ll pay them only half. They just looked at each other and simply nodded at me. They had this look of someone who has always been helpless and has resigned themselves to this fate for so long that they couldn’t imagine life any other way. I saw all of that, and but my frustration overrode that, and I gave them just half the agreed upon amount and sent them their way.</p>

<p>As soon as they closed the gate behind them, I felt incredibly sorry for them. It wasn’t their fault that they were not skilled. It wasn’t their fault that the contractor sent them our way. And us paying them just half the amount simply means that the contractor will take a larger cut of the money. Despite all of that, all they did was meekly nod. Next, I felt shame and guilt. Me paying them the entire amount would not make a slightest difference to my finances. I spend more going out with friends on a weekend evening.</p>

<p>All of this took about a minute to register, and I immediately called them back and gave them the full amount that was promised to them.</p>

<p>That look of helplessness and resignation stayed with me a long time. But I simply couldn’t understand it in it’s larger context. For a while, I saw this as a fault in their character that will get them swindled, and almost felt good about me not being one of the many who cheated them out of what they earned. Nonetheless, this event stayed with me, as I learned more, I kept recasting that experience with new sociological lenses. It took me years to recognize it as a natural consequence of multi-generational societal oppression, and with that recognize my own privilege.</p>]]></content><author><name>Srikanth Sastry</name><email>srikanth@sastry.name</email></author><category term="Personal" /><category term="reflection" /><category term="privilege" /><summary type="html"><![CDATA[For the first 23 years of my life, I was convinced that everything that came my way was hard earned, and it was despite the oppression against our community. At 23, I was working as a young software engineer in Bangalore. I needed the house deep cleaned, and a contractor said that he would send a couple of people over who would take care of it for us. I was about to get my first glimpse into the privilege that I had enjoyed all my life.]]></summary></entry><entry><title type="html">Reuse Code, Not Objects</title><link href="//srikanth.sastry.name/reuse-code-not-objects/" rel="alternate" type="text/html" title="Reuse Code, Not Objects" /><published>2021-07-17T02:01:41+00:00</published><updated>2021-07-17T02:01:41+00:00</updated><id>//srikanth.sastry.name/reuse-code-not-objects</id><content type="html" xml:base="//srikanth.sastry.name/reuse-code-not-objects/"><![CDATA[<!-- wp:image {"id":666} -->
<figure class="wp-block-image"><img src="https://srikanth.sastry.name/wp-content/uploads/2021/07/pexels-photo-5218009-edited.jpeg" alt="" class="wp-image-666" /></figure>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p>We all know of the importance of <a href="https://en.wikipedia.org/wiki/Code_reuse">code reuse</a> and <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">DRY</a> code. It is important to remember that this applies to code, and <em>not</em> to objects!<br />A common anti-pattern I see in stateful classes is something along the following lines:</p>
<!-- /wp:paragraph -->

<!-- wp:code -->
<pre class="wp-block-code"><code>class SomeStatefulClass {
  private ResponseType responseType;
  private final ErrMessages errMessages;
  
  public SomeStatefulClass() {
    this.ResponseType = null;
    this.errMessages = new ErrMessages();
  }
  
  public void init() {
    errMessages.clear();
  }
  
  public Response process(Request request) {
    try {
      // Process the request.
      // Update stats.
      // Update otherState.
      Response response = computeResponse();
      responseType = computeResponseType();
      return response;
    } catch (Exception e) {
      this.errMessages.append(e);
    }
    return null;
  }
  
  public LogMessages getErrMessages() {
    return this.errMessages;
  }
  
  public ResponseType getResponseType() {
    return responseType;
  }
}</code></pre>
<!-- /wp:code -->

<!-- wp:paragraph -->
<p>This design pattern is a major code smell. Ironically, such classes are prone to be <em>misused through reuse</em>. A common example of this is reusing the object within a loop:</p>
<!-- /wp:paragraph -->

<!-- wp:code -->
<pre class="wp-block-code"><code>public void process(List&lt;Request&gt; requests) {
  final SomeStatefulClass statefulObject
      = new SomeStatefulClass();
  Response response;
  for (Request request: requests) {
    statefulObject.init();
    response = statefulObject.process(request);
    appendResponse(response, statefulObject.getResponseType());
    
  }
}</code></pre>
<!-- /wp:code -->

<!-- wp:paragraph -->
<p>The issue here is subtle, but dangerous. Consider what happens if one of the requests in the list of requests passed to <code>process()</code> causes <code>statefulObject</code>to throw an exception inside <code>computeResponse()</code>. Dutifully, this exception is caught by <code>process()</code> and it returns <code>null</code>. However, note that the value of <code>responseType</code> in <code>statefulObject</code> was never modified by processing of this request, and therefore, it still hold the <code>ResponseType</code> of the previous request! Therefore, the line <code>appendResponse(response, statefulObject.getResponseType());</code> is now passing in a null response and the response type of the previous request!<br />These types of bugs are subtle and a pain to track down.<br />And this happened because we chose to reuse the <code>statefulObject</code>. If we were to use a new instance each time, this would not really be an issue.<br />Moral: If feasible, do not reuse objects; create new instances and throw them away when done!</p>
<!-- /wp:paragraph -->]]></content><author><name>Srikanth Sastry</name></author><category term="Professional" /><category term="design pattern" /><category term="software engineering" /><summary type="html"><![CDATA[We all know of the importance of code reuse and DRY code. It is important to remember that this applies to code, and not to objects!]]></summary></entry></feed>