<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://srikanth.sastry.name/feed.xml" rel="self" type="application/atom+xml" /><link href="https://srikanth.sastry.name/" rel="alternate" type="text/html" /><updated>2025-06-21T16:36:02+00:00</updated><id>https://srikanth.sastry.name/feed.xml</id><title type="html">Srikanth Sastry</title><subtitle>This is Srikanth Sastry&apos;s personal blog, where I share my thoughts on technology, programming, and life in general.  Join me on this journey of exploration and learning.</subtitle><entry><title type="html">Cyclomatic Complexity: How Low Can You Go?</title><link href="https://srikanth.sastry.name/reduce-cyclomatic-complexity/" rel="alternate" type="text/html" title="Cyclomatic Complexity: How Low Can You Go?" /><published>2025-06-17T00:00:00+00:00</published><updated>2025-06-17T00:00:00+00:00</updated><id>https://srikanth.sastry.name/reduce-cyclomatic-complexity</id><content type="html" xml:base="https://srikanth.sastry.name/reduce-cyclomatic-complexity/"><![CDATA[<h2 id="what-even-is-cyclomatic-complexity">What even <em>is</em> Cyclomatic Complexity?</h2>
<p>Ever spend 20 minutes trying to figure out why your bug fix or feature code isn‚Äôt triggering or being executed ‚Äî only to realize you missed a buried branch in someone‚Äôs 10-path function? That‚Äôs <a href="https://en.wikipedia.org/wiki/Cyclomatic_complexity">Cyclomatic Complexity</a> in action. Intuitively, you can think of Cyclomatic Complexity as the number of possible paths a single execution of a function can take.</p>

<p>For example, <code class="language-plaintext highlighter-rouge">a = b + c</code> has a cyclomatic complexity of one, and <code class="language-plaintext highlighter-rouge">a = b + c if foo else d + e</code> has a cyclomatic complexity of two: one path is when <code class="language-plaintext highlighter-rouge">foo</code> is <code class="language-plaintext highlighter-rouge">True</code> and the effective logic is <code class="language-plaintext highlighter-rouge">a = b + c</code>, and the other path is when <code class="language-plaintext highlighter-rouge">foo</code> is <code class="language-plaintext highlighter-rouge">False</code> and the effective logic is <code class="language-plaintext highlighter-rouge">a = d + e</code>.</p>

<h2 id="aint-got-no-time-heres-the-goods">Ain‚Äôt got no time? Here‚Äôs the goods.</h2>

<p>If you take just one thing away from this note, then let it be this.</p>

<blockquote>
  <p><strong>Strive to reduce the Cyclomatic Complexity of your code; your team and your future self will thank you!</strong></p>
</blockquote>

<h2 id="time-to-hit-the-brain-gym-bro">Time to hit the brain gym, bro</h2>
<p>As an exercise, I will let you figure out the cyclomatic complexity of the following piece of code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">env_val</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">...</span><span class="sh">'</span><span class="p">)</span>
<span class="n">switcher_val</span> <span class="o">=</span> <span class="bp">False</span>
<span class="k">if</span> <span class="n">env_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">jk_val</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">if</span> <span class="n">env_val</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">yes</span><span class="sh">"</span><span class="p">]:</span>
        <span class="n">env_val</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">env_val</span> <span class="o">=</span> <span class="bp">False</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">env_val</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">switch_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/switch/name/from/config</span><span class="sh">"</span>
    <span class="n">switcher_val</span> <span class="o">=</span> <span class="n">switcher</span><span class="p">.</span><span class="nf">check</span><span class="p">(</span><span class="n">switch_name</span><span class="p">,</span> <span class="n">switchval</span><span class="o">=</span><span class="n">region</span><span class="p">)</span>
<span class="k">if</span> <span class="n">env_val</span> <span class="ow">or</span> <span class="n">switcher_val</span><span class="p">:</span>
    <span class="nf">apply_some_config</span><span class="p">(</span><span class="n">job</span><span class="p">)</span>
</code></pre></div></div>

<p>I‚Äôll wait‚Ä¶ (Spoiler: It‚Äôs not pretty.)</p>

<p>Give up? Turns out, it is <code class="language-plaintext highlighter-rouge">4</code>: three if-checks contribute to three branching points, and the cyclomatic complexity is one more than that; <em>ergo</em> <code class="language-plaintext highlighter-rouge">4</code>.</p>

<p>Next, by spending no more than 60 seconds looking this code, can you tell me what exactly it is doing? BTW, this is real production code that I ran across when debugging some issue, and it took me a long while to make sure I knew exactly when and how the config is applied. It wasn‚Äôt obvious at all. If you can grok this in 60 seconds, take a bow!</p>

<h2 id="reeling-yet">Reeling yet?</h2>

<p>Anyway, making sense of functions with high cyclomatic complexity is annoying. It‚Äôs notoriously difficult to write tests with good coverage for these functions, and in general, they tend to be bug factories.</p>

<p>And yet ‚Äî somehow ‚Äî a lot of senior software engineers don‚Äôt seem to grok this. I keep seeing deeply nested <code class="language-plaintext highlighter-rouge">if-else</code> blocks, sometimes inside loops with <code class="language-plaintext highlighter-rouge">break</code>s and <code class="language-plaintext highlighter-rouge">continue</code>s, and it doesn‚Äôt seem to bother anyone! It‚Äôs like we‚Äôve collectively normalized this cognitive overhead.</p>

<p>Why?! Why are we putting up with this crap? It‚Äôd never fly in an interview.</p>

<h2 id="yo-lets-fix-it-up">Yo, let‚Äôs fix it up!</h2>
<p>Coming back to the above example, the confusion and ugliness of this code really got to me. It got so bad I considered dusting off a Karnaugh map. After some much needed grokking, I managed to simplify it down to a cyclomatic complexity of <code class="language-plaintext highlighter-rouge">2</code>! :)</p>

<p>In the end, here‚Äôs what that poor little code snippet was trying to do:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Apply config when '...' environment variable is True, else check the switch
</span><span class="n">__ENV_VARIABLE</span> <span class="o">=</span> <span class="sh">'</span><span class="s">...</span><span class="sh">'</span>
<span class="n">__SWITCHER_KEY</span> <span class="o">=</span> <span class="sh">'</span><span class="s">/switch/name/from/config</span><span class="sh">'</span>
<span class="k">def</span> <span class="nf">has_env_override</span><span class="p">():</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">__ENV_VARIABLE</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">val</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">{</span><span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">yes</span><span class="sh">"</span><span class="p">}</span>

<span class="nf">if </span><span class="p">(</span>
    <span class="nf">has_env_override</span><span class="p">()</span> <span class="ow">or</span> 
    <span class="n">switcher</span><span class="p">.</span><span class="nf">check</span><span class="p">(</span><span class="n">__SWITCHER_KEY</span><span class="p">,</span> <span class="n">switchval</span><span class="o">=</span><span class="n">region</span><span class="p">)</span>
<span class="p">):</span>
    <span class="nf">apply_some_config</span><span class="p">(</span><span class="n">job</span><span class="p">)</span>
</code></pre></div></div>

<p>Fewer paths, fewer bugs. Cleaner code. Happier teammates. What‚Äôs not to love?</p>]]></content><author><name>Srikanth Sastry</name></author><category term="Professional" /><category term="cyclomatic-complexity" /><category term="refactoring" /><category term="best-practices" /><summary type="html"><![CDATA[What even is Cyclomatic Complexity? Ever spend 20 minutes trying to figure out why your bug fix or feature code isn‚Äôt triggering or being executed ‚Äî only to realize you missed a buried branch in someone‚Äôs 10-path function? That‚Äôs Cyclomatic Complexity in action. Intuitively, you can think of Cyclomatic Complexity as the number of possible paths a single execution of a function can take.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://srikanth.sastry.name/images/cpu-in-maze-pixel-art.png" /><media:content medium="image" url="https://srikanth.sastry.name/images/cpu-in-maze-pixel-art.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">TDD for Bug Fixes</title><link href="https://srikanth.sastry.name/tdd-for-bug-fixes/" rel="alternate" type="text/html" title="TDD for Bug Fixes" /><published>2025-06-11T00:00:00+00:00</published><updated>2025-06-11T00:00:00+00:00</updated><id>https://srikanth.sastry.name/tdd-for-bug-fixes</id><content type="html" xml:base="https://srikanth.sastry.name/tdd-for-bug-fixes/"><![CDATA[<!-- ![](/images/bug-stabbing-software-engineer-in-the-back.png) -->

<p>I have seen way too many ‚Äòsenior‚Äô engineers get bug fixing wrong. It is common to see an engineer sent a pull request titled ‚Äúbug fix: <something>" and the PR has changes to the functional code that fixes the bug and a correspond test case that shows that the bug is fixed. If that sounds reasonable, THINK AGAIN ‚Äî you‚Äôve walked right into the classic trap!</something></p>

<p><strong>If you are sending PRs for bug fixes with functional code change and an added test case in the same PR/commit, then you are doing it wrong!</strong></p>

<p>The crux of the problem is the following: HOW DO YOU <em>KNOW</em> YOU‚ÄôRE SMASHING THAT BUG? HOW CAN YOU BE SURE YOUR TEST ISN‚ÄôT A DUD?! Your answer better not be <em>VIBE CHECKS</em> or just <em>STARING REALLY HARD</em>! If you are having to deploy your entire service/library and run an end-to-end test to demonstrate correctness, then you are doing too much, and you still haven‚Äôt demonstrated that the unit test actually captures the previously errneous behavior.</p>

<p>There is this shiny little concept called <a href="https://en.wikipedia.org/wiki/Test-driven_development">Test Driven Development (TDD)</a> that is mighty useful here. You can peruse the wikipedia link to figure out what TDD is exactly. This note will show you how to use TDD for bug fixes.</p>

<p>Here are simple steps to fixing bugs using TDD:</p>

<ol>
  <li>
    <p>üïµÔ∏è Discover the bug. BAM! There it is! Your nemesis!</p>
  </li>
  <li>
    <p>üß™ Create a PR that creates a new unit test that exposes the unit test. YAWZA!</p>
  </li>
  <li>
    <p>üîß Create a second PR on top the first PR that makes the functional code change and changes the expectation on the unit test accordingly. That should squash the bug! KAPOW!</p>
  </li>
  <li>
    <p>üí∞ Justice is served! PROFIT!</p>
  </li>
</ol>

<p><img src="/images/tdd-bug-lifecycle.png" alt="" /></p>

<p>Still not sure? Let‚Äôs demonstrate this with an example. Say, there is a bug that you discovered and know how to fix it.</p>

<p>First, you create a PR that demonstrates the bug by invoking your SUT with the offending input, and sets the expected value to be <em>incorrect</em> so that the test case actually <em>passes</em> with this incorrect value; thus demonstrating the bug.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TestSUT</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">test_bug_b12345</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="sh">'''</span><span class="s">
        Test to expose bug b12345
        </span><span class="sh">'''</span>
        <span class="c1"># Arrange
</span>        <span class="n">sut</span> <span class="o">=</span> <span class="nc">SUT</span><span class="p">(...)</span>
        
        <span class="c1"># Act
</span>        <span class="n">actual</span> <span class="o">=</span> <span class="n">sut</span><span class="p">.</span><span class="nf">test_method</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="sh">"</span><span class="s">bad-input</span><span class="sh">"</span><span class="p">)</span>

        <span class="c1"># Assert
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="sh">"</span><span class="s">bad buggy output</span><span class="sh">"</span><span class="p">)</span>
        <span class="c1"># The assertion above demonstartes the bug b12345
</span>        <span class="c1"># The right expected value should be "correct output".
</span>        <span class="c1"># self.assertEqual(actual, "correct output")
</span>        
</code></pre></div></div>

<p>You can send that PR out for review and merge it in. Now you have a solid proof that you have found a bug, and reproduced it.</p>

<p>Next, you have a new PR that fixes that bug. If you bug fix is correct, then the test <code class="language-plaintext highlighter-rouge">test_bug_b12345</code> should not start failing. The output of <code class="language-plaintext highlighter-rouge">sut.test_method(input="bad-input")</code> should be <code class="language-plaintext highlighter-rouge">"correct output"</code> and not <code class="language-plaintext highlighter-rouge">"bad buggy output"</code>. So, you now modify the unit test <code class="language-plaintext highlighter-rouge">test_bug_b12345</code> in that same PR that looks as follows:</p>
<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    def test_bug_b12345(self) -&gt; None:
        '''
        Test to expose bug b12345
        '''
        # Arrange
        sut = SUT(...)
        
        # Act
        actual = sut.test_method(input="bad-input")
<span class="err">
</span>        # Assert
<span class="gd">-       self.assertEqual(actual, "bad buggy output")
-       # The assertion above demonstartes the bug b12345
-       # The right expected value should be "correct output".
-       # self.assertEqual(actual, "correct output")
</span><span class="gi">+       self.assertEqual(actual, "correct output")
</span></code></pre></div></div>

<p>Now your test should pass. This second PR is conclusive proof that your diff now fixes the bug! So, merge it in. Deploy with confidence. <strong>BOOM ‚Äî PROFIT!</strong></p>]]></content><author><name></name></author><category term="Professional" /><category term="test driven development" /><category term="tdd" /><category term="bug fixing" /><category term="testing" /><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://srikanth.sastry.name/images/bug-stabbing-software-engineer-in-the-back.png" /><media:content medium="image" url="https://srikanth.sastry.name/images/bug-stabbing-software-engineer-in-the-back.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Let Sleeping Engineers Lie: Why Your Alerts Should Match Your SEVs</title><link href="https://srikanth.sastry.name/sync-your-alerts-to-your-sev-criteria/" rel="alternate" type="text/html" title="Let Sleeping Engineers Lie: Why Your Alerts Should Match Your SEVs" /><published>2025-06-07T00:00:00+00:00</published><updated>2025-06-07T00:00:00+00:00</updated><id>https://srikanth.sastry.name/let-sleeping-engineers-lie-why-your-alerts-should-match-your-sevs</id><content type="html" xml:base="https://srikanth.sastry.name/sync-your-alerts-to-your-sev-criteria/"><![CDATA[<!-- ![](/images/sleepy-engineer-cursing-laptop.png) -->
<p>At work, I had a customer team that aspired to be <em>‚Äúcustomer first.‚Äù</em> To them, that meant fixing issues <em>before</em> they became SEVs. That was all and good, except that the way they went about it was to fire alerts well <em>before</em> their SLOs were close to being breached. Of course, I knew nothing about it until I was the receiving end of their ‚Äòaspiration‚Äô.</p>

<p>It‚Äôs 4 AM, and I am in deep sleep. Suddenly, my phone, overriding all silencing setting starts ringing like there is no tomorrow. Naturally, I was being paged. I wake up bleary eyed, acknowledge the page, and join the team channel. Helpfully, the customer team oncall has message for me: <strong>‚ÄúYour service has a latency spike. Please look into it.‚Äù</strong></p>

<p>I drag myself to a laptop, check the graphs, and yes ‚Äî there <em>was</em> a p99 latency spike, it lasted about half hour, and is already waning. Our SLOs were fine; our latency SLOs at these latency levels don‚Äôt breach for another 30 minutes. I double-checked <em>their</em> SEV criteria, and they are also still green! So why the 4 AM fire drill?</p>

<p>Turns out, they‚Äôd set up their alerts to go off when their p99 latency went above the normal limits for 30 minutes, but their SLO wouldn‚Äôt be breached until the elevated p99 persisted for 60 minutes. A twitcy alert if you ask me!</p>

<p>Their on-call had no idea what to do with the alert, saw my service mentioned, and did the classic move:</p>
<blockquote>
  <p><em>‚ÄúWhen in doubt, escalate!‚Äù</em></p>
</blockquote>

<p>So now <em>I‚Äôm</em> awake, trying to make sense of a 30-minute p99 latency increase that is fixing itself. I asked:</p>

<blockquote>
  <p><strong>‚ÄúWhere‚Äôs the SEV‚Äô?</strong></p>
</blockquote>

<p>I imagine the scene something like this.
<img src="/images/where-sev-where-impact.jpg" alt="" /></p>

<p>Silence. Five minutes later, ‚ÄúHere is the SEV number‚Ä¶‚Äù The SEV was created two minutes ago. Facepalm!</p>

<p>Here‚Äôs what actually happened:</p>
<ul>
  <li>The latency spike lasted about 30 minutes.</li>
  <li>The system auto-healed.</li>
  <li>The affected service was user-facing, but this was deep in the off-hours.</li>
  <li>Total estimated user impact: somewhere between <em>‚Äúnegligible‚Äù</em> and <em>‚Äúnone.‚Äù</em></li>
</ul>

<p>We could‚Äôve all just slept through it and looked at it with fresh eyes in the morning. Instead, two engineers got pulled into zombie mode to stare at graphs that improved all by themselves. It was like debugging a ghost.</p>

<h3 id="moral-of-the-story">Moral of the story:</h3>
<p>If your alert is going to wake someone up at 4 AM, it better be for something that <em>actually</em> matters. If there‚Äôs no SEV, no SLO breach, and no clear user impact ‚Äî maybe let sleeping engineers lie.</p>]]></content><author><name>Srikanth Sastry</name></author><category term="Professional" /><category term="alerts" /><category term="monitoring" /><category term="SEV" /><summary type="html"><![CDATA[At work, I had a customer team that aspired to be ‚Äúcustomer first.‚Äù To them, that meant fixing issues before they became SEVs. That was all and good, except that the way they went about it was to fire alerts well before their SLOs were close to being breached. Of course, I knew nothing about it until I was the receiving end of their ‚Äòaspiration‚Äô.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://srikanth.sastry.name/images/sleepy-engineer-cursing-laptop.png" /><media:content medium="image" url="https://srikanth.sastry.name/images/sleepy-engineer-cursing-laptop.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The Law of Demeter and unit tests</title><link href="https://srikanth.sastry.name/law-of-demeter-and-unit-tests/" rel="alternate" type="text/html" title="The Law of Demeter and unit tests" /><published>2022-07-22T00:00:00+00:00</published><updated>2022-07-22T00:00:00+00:00</updated><id>https://srikanth.sastry.name/the-law-of-demeter-and-unit-tests</id><content type="html" xml:base="https://srikanth.sastry.name/law-of-demeter-and-unit-tests/"><![CDATA[<!-- ![](/images/demeter-sketch-bw.jpg) -->
<p>The <a href="https://en.wikipedia.org/wiki/Law_of_Demeter">Law of Demeter</a> essentially says that each unit should only talk to its ‚Äòimmediate friends‚Äô or ‚Äòimmediate dependencies‚Äô, and in spirit, it is pointing to the principle that each unit only have the information it needs to meet its purpose. In that spirit, the Law of Demeter takes two forms that are relevant to making your code more testable: (1) object chains, and (2) fat parameters.</p>

<h2 id="object-chains">Object Chains</h2>

<p>This is the more classic violation of the Law of Demeter<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>. This happens when a class <code class="language-plaintext highlighter-rouge">C</code> has a dependency <code class="language-plaintext highlighter-rouge">D</code>, and <code class="language-plaintext highlighter-rouge">D</code> has method <code class="language-plaintext highlighter-rouge">m</code> that returns an instance of another class <code class="language-plaintext highlighter-rouge">A</code>. The violation happens when <code class="language-plaintext highlighter-rouge">C</code> accesses <code class="language-plaintext highlighter-rouge">A</code> and calls a method in <code class="language-plaintext highlighter-rouge">A</code>. Note that only <code class="language-plaintext highlighter-rouge">D</code> is the ‚Äòimmediate‚Äô collaborator/dependency of <code class="language-plaintext highlighter-rouge">C</code>, and not <code class="language-plaintext highlighter-rouge">A</code>. The Law of Demeter says that <code class="language-plaintext highlighter-rouge">C</code> should not be accessing the method in <code class="language-plaintext highlighter-rouge">A</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># A violation of the Law of Demeter looks as follows.
## Example 1:
</span><span class="n">c</span><span class="p">.</span><span class="n">d</span><span class="p">.</span><span class="nf">m</span><span class="p">().</span><span class="nf">methodInA</span><span class="p">()</span>

<span class="c1">## Example 2:
</span><span class="n">d</span><span class="p">:</span> <span class="n">D</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">d</span>
<span class="n">a</span><span class="p">:</span> <span class="n">A</span> <span class="o">=</span> <span class="n">d</span><span class="p">.</span><span class="nf">m</span><span class="p">()</span>
<span class="n">a</span><span class="p">.</span><span class="nf">methodInA</span><span class="p">()</span>
</code></pre></div></div>

<p>What is the problem with violating the Law of Demeter?  Consider the following production code:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">UpdateKVStore</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">client</span><span class="p">:</span> <span class="n">KVStoreClient</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">client</span>
        
    <span class="k">def</span> <span class="nf">update_value</span><span class="p">(</span><span class="n">new_content</span><span class="p">:</span> <span class="n">Content</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Status</span><span class="p">:</span>
        <span class="n">transaction</span><span class="p">:</span> <span class="n">KVStoreClient</span><span class="p">.</span><span class="n">Transaction</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="nf">new_transaction</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">transaction</span><span class="p">.</span><span class="nf">get_content</span><span class="p">()</span> <span class="o">==</span> <span class="n">new_content</span><span class="p">:</span>
            <span class="c1"># Nothing to update
</span>            <span class="n">transaction</span><span class="p">.</span><span class="nf">end</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">Status</span><span class="p">.</span><span class="n">SUCCESS_UNCHANGED</span>
        <span class="n">mutation_request</span><span class="p">:</span> <span class="n">KVStoreClient</span><span class="p">.</span><span class="n">MutationRequest</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">transaction</span><span class="p">.</span><span class="nf">mutation_request</span><span class="p">().</span><span class="nf">set_content</span><span class="p">(</span><span class="n">new_content</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">mutation</span> <span class="o">=</span> <span class="n">mutation_request</span><span class="p">.</span><span class="nf">prepare</span><span class="p">()</span>
        <span class="n">status</span><span class="p">:</span> <span class="n">KVStoreClient</span><span class="p">.</span><span class="n">Mutation</span> <span class="o">=</span> <span class="n">mutation</span><span class="p">.</span><span class="nf">land</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">status</span>
</code></pre></div></div>

<p>Now how would you unit test this? The test doubles for testing this code will look something like this</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mock_client</span> <span class="o">=</span> <span class="nc">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">KVStoreClient</span><span class="p">)</span>
<span class="n">mock_transaction</span> <span class="o">=</span> <span class="nc">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">KVStoreClient</span><span class="p">.</span><span class="n">Transaction</span><span class="p">)</span>
<span class="n">mock_mutation_request</span> <span class="o">=</span> <span class="nc">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">KVStoreClient</span><span class="p">.</span><span class="n">MutationRequest</span><span class="p">)</span>
<span class="n">mock_mutation</span> <span class="o">=</span> <span class="nc">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">KVStoreClient</span><span class="p">.</span><span class="n">Mutation</span><span class="p">)</span>

<span class="n">mock_client</span><span class="p">.</span><span class="n">new_transaction</span><span class="p">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">mock_transaction</span>
<span class="n">mock_transaction</span><span class="p">.</span><span class="n">mutation_request</span><span class="p">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">mock_mutation_request</span>
<span class="n">mock_mutation_request</span><span class="p">.</span><span class="n">prepare</span><span class="p">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">mock_mutation</span>
</code></pre></div></div>

<p>Now you can see how much the class <code class="language-plaintext highlighter-rouge">UpdateKVStore</code> and its unit tests need to know about the internals of the <code class="language-plaintext highlighter-rouge">KVStoreClient</code>. Any changes to how the <code class="language-plaintext highlighter-rouge">KVStoreClient</code> implements the transaction will cascade into test failures on all its clients! That‚Äôs a recipe for a <a href="https://srikanth.sastry.name/unit-test-attributes-and-their-trade-offs/">low accuracy</a> test suite.</p>

<p>There are a few ways to address this. Instead, if <code class="language-plaintext highlighter-rouge">KVStoreClient</code> could be recast as a <code class="language-plaintext highlighter-rouge">Transaction</code> factory, and then encapsulate all operations associated with the transactions within the <code class="language-plaintext highlighter-rouge">Transaction</code> class, then <code class="language-plaintext highlighter-rouge">UpdateKVStore</code> can be modified as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">UpdateKVStore</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">client</span><span class="p">:</span> <span class="n">KVStoreClient</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">client</span>  <span class="c1"># Now a Factory class for Transaction.
</span>        
    <span class="k">def</span> <span class="nf">update_value</span><span class="p">(</span><span class="n">new_content</span><span class="p">:</span> <span class="n">Content</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Status</span><span class="p">:</span>
        <span class="n">transaction</span><span class="p">:</span> <span class="n">KVStoreClient</span><span class="p">.</span><span class="n">Transaction</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="nf">new_transaction</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">transaction</span><span class="p">.</span><span class="nf">get_content</span><span class="p">()</span> <span class="o">==</span> <span class="n">new_content</span><span class="p">:</span>
            <span class="c1"># Nothing to update
</span>            <span class="n">transaction</span><span class="p">.</span><span class="nf">end</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">Status</span><span class="p">.</span><span class="n">SUCCESS_UNCHANGED</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">transaction</span><span class="p">.</span><span class="nf">update_and_land</span><span class="p">(</span><span class="n">new_content</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">status</span>
</code></pre></div></div>

<p>When testing the new <code class="language-plaintext highlighter-rouge">UpdateKVStore</code>, you only need to replace the <code class="language-plaintext highlighter-rouge">KVStoreClient</code> and the <code class="language-plaintext highlighter-rouge">Transaction</code>, both of which are (explicit or implicit) direct dependencies, with test doubles. This makes the code much easier and straightforward to test.</p>

<h2 id="fat-parameters">Fat Parameters</h2>

<p>While the anti-pattern of ‚Äòfat parameters‚Äô does follow directly from the Law of Demeter, it does follow from the spirit of passing in only the information that the class needs to perform its function. So, what are fat parameters? They are data objects that as passed in as an argument to a class, and they contain more information than what is needed by the class.</p>

<p>For instance, say you have a class <code class="language-plaintext highlighter-rouge">EmailDispatcher</code> whose method <code class="language-plaintext highlighter-rouge">setRecipient</code> only needs a customer name and email address. The method signature for <code class="language-plaintext highlighter-rouge">setRecipient</code> should only require the name and email, and not the entire <code class="language-plaintext highlighter-rouge">Customer</code> object that contains a whole lot more.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Customer</span><span class="p">:</span>
    <span class="p">...</span> <span class="c1"># data class members.
</span>    <span class="k">def</span> <span class="nf">getFullName</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">getEmail</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">getPhysicalAddress</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">getPostalCode</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">getCountry</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">getState</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">getCustomerId</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="bp">...</span>
    <span class="c1"># and so on.
</span>    
 <span class="k">class</span> <span class="nc">EmailDispatcher</span><span class="p">:</span>
     <span class="bp">...</span>
     <span class="k">def</span> <span class="nf">setRecipient</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">email</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
         <span class="bp">...</span>
     <span class="k">def</span> <span class="nf">setRecipientWithFatParameter</span><span class="p">(</span><span class="n">customer</span><span class="p">:</span> <span class="n">Customer</span><span class="p">):</span>
         <span class="bp">...</span>
     <span class="k">def</span> <span class="nf">sendMessage</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">message</span><span class="p">:</span> <span class="n">Message</span><span class="p">):</span>
         <span class="bp">...</span>
</code></pre></div></div>

<p>In the pseudocode above, the class <code class="language-plaintext highlighter-rouge">EmailDispatcher</code> has two methods <code class="language-plaintext highlighter-rouge">setRecipient</code> and <code class="language-plaintext highlighter-rouge">setRecipientWithFatParameter</code>. The former uses only the information it needs, and the latter passed in the entire <code class="language-plaintext highlighter-rouge">Customer</code> object as a fat parameter.</p>

<p>The convenience of passing in the entire <code class="language-plaintext highlighter-rouge">Customer</code> object is straightforward. It allows gives you a simple method signature. It makes it easier for the method to evolve to use richer information about the customer without needing to change its API contract. It allows you to define a common <code class="language-plaintext highlighter-rouge">Dispatcher</code> interface with multiple <code class="language-plaintext highlighter-rouge">Dispatcher</code>s that use different properties of the <code class="language-plaintext highlighter-rouge">Customer</code> class.</p>

<p>However, when it comes to unit testing, such fat parameters present a problem. Consider how you would test the <code class="language-plaintext highlighter-rouge">EmailDispatcher</code>‚Äôs <code class="language-plaintext highlighter-rouge">setRecipientWithFatParameter</code> method. The tests will need to create fake <code class="language-plaintext highlighter-rouge">Customer</code> objects. So, your fake <code class="language-plaintext highlighter-rouge">Customers</code> might look like this:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fakeCustomer</span> <span class="o">=</span> <span class="nc">Customer</span><span class="p">(</span>
    <span class="n">first_name</span><span class="o">=</span><span class="sh">"</span><span class="s">bob</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">last_name</span><span class="o">=</span><span class="sh">"</span><span class="s">marley</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">email</span><span class="o">=</span><span class="sh">"</span><span class="s">bob@doobie.com</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">address</span><span class="o">=</span><span class="nc">Address</span><span class="p">(</span>
        <span class="sh">"</span><span class="s">420 High St.</span><span class="sh">"</span><span class="p">,</span> 
      <span class="sh">""</span><span class="p">,</span> 
      <span class="sh">"</span><span class="s">Mary Jane</span><span class="sh">"</span><span class="p">,</span> 
      <span class="sh">"</span><span class="s">Ganga Nation</span><span class="sh">"</span><span class="p">,</span> 
      <span class="sh">"</span><span class="s">7232</span><span class="sh">"</span>
    <span class="p">),</span> 
    <span class="nb">id</span><span class="o">=</span><span class="mi">12345</span><span class="p">,</span> 
    <span class="n">postal_code</span><span class="o">=</span><span class="sh">"</span><span class="s">7232</span><span class="sh">"</span><span class="p">,</span> 
    <span class="bp">...</span>
<span class="p">)</span>
</code></pre></div></div>

<p>When someone reads this unit test, do they know what is relevant here? Does it matter that the second parameter of <code class="language-plaintext highlighter-rouge">address</code> is empty string? Should the last parameter of <code class="language-plaintext highlighter-rouge">address</code> match the value of <code class="language-plaintext highlighter-rouge">postal_code</code>? While we might be able to guess it in this case, it gets more confusing in cases where the fat parameter is encapsulating a much more complicated entity, such as a database table.</p>

<p>When refactoring or making changes to the <code class="language-plaintext highlighter-rouge">EmailDispatcher</code>, if the unit test fails, then figuring out why the test failed becomes a non-trivial exercise, and could end up slowing you down a lot more than you expected. All this just leads to high maintenance costs for tests, low readability <sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>, poor DevX, and limited benefits.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>You can read about it <a href="https://wouterdekort.com/2012/03/27/unit-testing-hell-or-heaven/">here</a>, <a href="https://hermanradtke.com/2010/01/17/unit-testing-and-the-law-of-demeter.html/">here</a>, <a href="https://wiki.c2.com/?LawOfDemeterMakesUnitTestsEasier">here</a>, and <a href="https://testing.googleblog.com/2008/07/breaking-law-of-demeter-is-like-looking.html">here</a>, and really just search for ‚ÄúLaw of Demeter‚Äù on the Internet¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>For more details on why we should care about readability, see the section on Readability <a href="https://srikanth.sastry.name/dry-unit-tests-are-bad/">here</a>.¬†<a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="Professional" /><category term="unit tests" /><category term="software engineering" /><summary type="html"><![CDATA[The Law of Demeter essentially says that each unit should only talk to its ‚Äòimmediate friends‚Äô or ‚Äòimmediate dependencies‚Äô, and in spirit, it is pointing to the principle that each unit only have the information it needs to meet its purpose. In that spirit, the Law of Demeter takes two forms that are relevant to making your code more testable: (1) object chains, and (2) fat parameters.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://srikanth.sastry.name/images/demeter-sketch-bw.jpg" /><media:content medium="image" url="https://srikanth.sastry.name/images/demeter-sketch-bw.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">‚ÄòPrivatize‚Äô your classes for better unit testing</title><link href="https://srikanth.sastry.name/privatize-your-classes-for-better-unit-testing/" rel="alternate" type="text/html" title="‚ÄòPrivatize‚Äô your classes for better unit testing" /><published>2022-07-11T00:00:00+00:00</published><updated>2022-07-11T00:00:00+00:00</updated><id>https://srikanth.sastry.name/privatize-your-classes-for-better-unit-testing</id><content type="html" xml:base="https://srikanth.sastry.name/privatize-your-classes-for-better-unit-testing/"><![CDATA[<!-- ![](images/amber-iceberg-under-water.jpg) -->
<p>You service may be massive, but it‚Äôs public API surface is pretty small; it has just a handful of APIs/endpoints. Everything else behind those APIs are ‚Äòprivate‚Äô and ‚Äòimplementation details‚Äô. It is highly advisable to follow this pattern even when designing the implementation of your service, almost like a fractal. This will pay dividends in the quality of your test suite.</p>

<p>For instance, you service implementation should be split into ‚Äòmodules‚Äô where each module has a well defined API through which other modules interact with it. This API boundary has to be strict. Avoid the temptation of breaking this abstraction because your module need this ‚Äòone tiny bit‚Äô of information that is available inside the implementation of another module. You will regret breaking encapsulation, I guarantee it!</p>

<p>If you follow this pattern, you will eventually reach a class that has a public API, has all of its external/shared dependencies shared, and delegates a lot of it‚Äôs business logic and complex computation to multiple ‚Äòprivate‚Äô classes that are practically hermetic and have no external/shared dependencies. At this point, treat all these ‚Äòprivate‚Äô classes as, well, private. That is, DO NOT WRITE UNIT TESTS FOR SUCH CLASSES!</p>

<p>Yes, that statement seems to fly in the face of all things sane about software testing, but it is a sane statement, nonetheless. These private classes should be tested indirectly via unit tests for the public class that they serve/support. This will make your tests a lot more accurate. Let me explain.</p>

<p>Say, you have a public class <code class="language-plaintext highlighter-rouge">CallMe</code> and it uses a private class <code class="language-plaintext highlighter-rouge">HideMe</code>, and furthermore, <code class="language-plaintext highlighter-rouge">HideMe</code> is used only by <code class="language-plaintext highlighter-rouge">CallMe</code>, and the software design enforces this restriction. Assume that both <code class="language-plaintext highlighter-rouge">CallMe</code> and <code class="language-plaintext highlighter-rouge">HideMe</code> have their own unit tests, and the tests do an excellent job. At this point, there is a new requirement that necessitates that we refactor <code class="language-plaintext highlighter-rouge">CallMe</code>‚Äôs implementation, and as part of that refactoring, we need to modify the API contract between <code class="language-plaintext highlighter-rouge">CallMe</code> and <code class="language-plaintext highlighter-rouge">HideMe</code>. Since <code class="language-plaintext highlighter-rouge">HideMe</code>‚Äôs only  caller is <code class="language-plaintext highlighter-rouge">CallMe</code>, it is completely safe to treat this API contract as an implementation detail and modify it as we see fit. Since we are modifying the specification of <code class="language-plaintext highlighter-rouge">HideMe</code>, we have to change the tests for <code class="language-plaintext highlighter-rouge">HideMe</code> as well.</p>

<p>Now, you run the tests, and the tests for <code class="language-plaintext highlighter-rouge">HideMe</code> fail. What information does that give you? Does that mean that there is a bug in <code class="language-plaintext highlighter-rouge">HideMe</code>; or does it mean that we did not modify the tests correctly? You cannot determine this until you either manually inspect <code class="language-plaintext highlighter-rouge">HideMe</code>‚Äôs test code, or until you run the tests for <code class="language-plaintext highlighter-rouge">CallMe</code>. If <code class="language-plaintext highlighter-rouge">CallMe</code>‚Äôs tests fail, then (since this is a refactoring diff) there must be a bug in <code class="language-plaintext highlighter-rouge">HideMe</code> and/or <code class="language-plaintext highlighter-rouge">CallMe</code>, but if the tests don‚Äôt fail, then it must be an issue in <code class="language-plaintext highlighter-rouge">HideMe</code>‚Äôs tests.</p>

<p>Thus, it turns out that the failure in <code class="language-plaintext highlighter-rouge">HideMe</code> tests gives you no additional information compared to failure in <code class="language-plaintext highlighter-rouge">CallMe</code>‚Äôs tests. Thus, tests for <code class="language-plaintext highlighter-rouge">HideMe</code> have zero benefits and a non-zero maintenance cost! In other words, testing <code class="language-plaintext highlighter-rouge">HideMe</code> directly is useless!</p>

<p>By aggressively refactoring your code to push as much of you logic into private classes, you are limiting the API surface of your software that needs direct testing, and simultaneously, ensuring that your tests suite is not too large, has very <a href="/unit-test-attributes-and-their-trade-offs/">high accuracy, with reasonable completeness</a>.</p>]]></content><author><name></name></author><category term="Professional" /><category term="unit tests" /><category term="software engineering" /><category term="refactoring" /><summary type="html"><![CDATA[You service may be massive, but it‚Äôs public API surface is pretty small; it has just a handful of APIs/endpoints. Everything else behind those APIs are ‚Äòprivate‚Äô and ‚Äòimplementation details‚Äô. It is highly advisable to follow this pattern even when designing the implementation of your service, almost like a fractal. This will pay dividends in the quality of your test suite.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://srikanth.sastry.name/images/amber-iceberg-under-water.jpg" /><media:content medium="image" url="https://srikanth.sastry.name/images/amber-iceberg-under-water.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Tests should be isolated from each other; not coupled</title><link href="https://srikanth.sastry.name/tests-should-be-isolated-not-coupled/" rel="alternate" type="text/html" title="Tests should be isolated from each other; not coupled" /><published>2022-07-03T00:00:00+00:00</published><updated>2022-07-03T00:00:00+00:00</updated><id>https://srikanth.sastry.name/coupled-tests</id><content type="html" xml:base="https://srikanth.sastry.name/tests-should-be-isolated-not-coupled/"><![CDATA[<!-- ![](/images/carabiners-connected.jpg) -->
<p>Almost <a href="/defining-unit-tests-two-schools-of-thought/">by definition</a> unit tests should be <em>isolated</em> from its (external, shared) dependencies. But, equally importantly, unit tests should also be isolated <em>from each other</em>. When one test starts to affect another test, the two tests are said to be <em>coupled</em>. Alternatively, if changes to one test <em>can</em> negatively impact the correctness of another test, then the two tests are said to be <em>coupled</em>.</p>

<p>Coupled tests are problematic in two ways.</p>

<ol>
  <li><em>Tests become less readable.</em> Reading the code for a single unit test does not necessarily communicate what the test does. We also need to understand the ‚Äòcoupling‚Äô between that test and other tests to grok what a single test does. This coupling can be subtle and not easy to follow.</li>
  <li><em>Tests become less <a href="/unit-test-attributes-and-their-trade-offs/">accurate</a>.</em> When one test affects another, it becomes difficult to make changes to a single test in isolation. For instance, if a diff makes changes to the some production and test code, and then a test fails, then it is not always clear why the test failed. The failure could due to a bug, or an artifact the coupled tests. Thus, your tests are no longer trustworthy, and therefore, less accurate.</li>
</ol>

<p>Coupling can happen in many ways. The obvious ones include (1) using the same shared dependency (like when you use the same temp file name in all tests), and (2) relying on the post-condition of one test as a precondition of another test. Such cases are also obvious to detect, and to fix. There are two more following ways in which tests can be coupled; but these are more subtle, and more prevalent.</p>

<ol>
  <li>Precondition setting in test fixtures</li>
  <li>Parameterized tests for heterogeneous tests</li>
</ol>

<p>The rest of this note is focused on the above two anti-patterns of test coupling.</p>

<h2 id="coupling-through-test-fixtures">Coupling through test fixtures</h2>

<p>Say, your SUT has a dependency called <code class="language-plaintext highlighter-rouge">Helper</code>, and initially, for the two tests in your unit tests for the SUT, you initialize your <code class="language-plaintext highlighter-rouge">Helper</code> stub with contents <code class="language-plaintext highlighter-rouge">valueA</code>, and <code class="language-plaintext highlighter-rouge">valueB</code>. Since both tests share the same initial state, you include the initialization code in the <code class="language-plaintext highlighter-rouge">SetUp</code> of the unit tests.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SUTTestCase</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">setUp</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span> <span class="o">=</span> <span class="nc">StubHelper</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">.</span><span class="nf">add_contents</span><span class="p">([</span><span class="n">valueA</span><span class="p">,</span> <span class="n">valueB</span><span class="p">])</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sut</span> <span class="o">=</span> <span class="nc">SUT</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">test_behavior1</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>  <span class="c1"># Assumes self.helper set with contents=[valueA, valueB]
</span>    
    <span class="k">def</span> <span class="nf">test_behavior2</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>  <span class="c1"># Assumes self.helper set with contents=[valueA, valueB]
</span></code></pre></div></div>

<p>Next, you modify SUT to add features to it. In order to test those features, the <code class="language-plaintext highlighter-rouge">Helper</code> stub needs to include <code class="language-plaintext highlighter-rouge">controllerA</code>. But these are useful only in the new tests being added. However, looking at the unit test you already have, it is easiest to to simply add <code class="language-plaintext highlighter-rouge">controllerA</code> to <code class="language-plaintext highlighter-rouge">self.helper</code>. So, your unit tests look as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SUTTestCase</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">setUp</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span> <span class="o">=</span> <span class="nc">StubHelper</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">.</span><span class="nf">add_contents</span><span class="p">([</span><span class="n">valueA</span><span class="p">,</span> <span class="n">valueB</span><span class="p">])</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">.</span><span class="nf">add_controller</span><span class="p">(</span><span class="n">controllerA</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sut</span> <span class="o">=</span> <span class="nc">SUT</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">test_behavior1</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>  <span class="c1"># Assumes self.helper set with contents=[valueA, valueB]
</span>             <span class="c1"># But this test assumes nothing about self.helper's controller
</span>
    <span class="k">def</span> <span class="nf">test_behavior2</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>  <span class="c1"># Assumes self.helper set with contents=[valueA, valueB]
</span>             <span class="c1"># But this test assumes nothing about self.helper's controller
</span>
    <span class="k">def</span> <span class="nf">test_behavior3</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>  <span class="c1"># Assumes self.helper set with contents=[valueA, valueB], and controller=controllerA
</span>
    <span class="k">def</span> <span class="nf">test_behavior4</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>  <span class="c1"># Assumes self.helper set with contents=[valueA, valueB], and controller=controllerA
</span></code></pre></div></div>

<p>Then you discover a gap in testing that requires the initial state of the <code class="language-plaintext highlighter-rouge">Helper</code> stub to have just the content <code class="language-plaintext highlighter-rouge">valueA</code> and include <code class="language-plaintext highlighter-rouge">controllerA</code>. Now, when adding this new unit test to suite, the simplest way to do this would be to remove <code class="language-plaintext highlighter-rouge">valueB</code> from <code class="language-plaintext highlighter-rouge">self.helper</code> at the start of the new test. So, now, your test suite looks as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SUTTestCase</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">setUp</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span> <span class="o">=</span> <span class="nc">StubHelper</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">.</span><span class="nf">add_contents</span><span class="p">([</span><span class="n">valueA</span><span class="p">,</span> <span class="n">valueB</span><span class="p">])</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">.</span><span class="nf">add_controller</span><span class="p">(</span><span class="n">controllerA</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sut</span> <span class="o">=</span> <span class="nc">SUT</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">test_behavior1</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>  <span class="c1"># Assumes self.helper set with contents=[valueA, valueB]
</span>             <span class="c1"># But this test assumes nothing about self.helper's controller
</span>
    <span class="k">def</span> <span class="nf">test_behavior2</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>  <span class="c1"># Assumes self.helper set with contents=[valueA, valueB]
</span>             <span class="c1"># But this test assumes nothing about self.helper's controller
</span>
    <span class="k">def</span> <span class="nf">test_behavior3</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>  <span class="c1"># Assumes self.helper set with contents=[valueA, valueB], and controller=controllerA
</span>
    <span class="k">def</span> <span class="nf">test_behavior4</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="p">...</span>  <span class="c1"># Assumes self.helper set with contents=[valueA, valueB], and controller=controllerA
</span>
    <span class="k">def</span> <span class="nf">test_behavior5</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Assumes self.helper set with contents=[valueA, valueB] (because of other tests' setup)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">.</span><span class="nf">remove_content</span><span class="p">(</span><span class="n">valueB</span><span class="p">)</span>
        <span class="c1"># Now assumes self.helper set with contents=[valueA]
</span>        <span class="p">...</span>  
</code></pre></div></div>

<p>Let pause here and inspect the state of the unit test. The tests are coupled. Why? Because modifying one test ends up affecting other tests. In the example above, if we replace <code class="language-plaintext highlighter-rouge">self.helper.add_contents([valueA, valueB])</code> with <code class="language-plaintext highlighter-rouge">self.helper.add_contents(valueA)</code> for tests <code class="language-plaintext highlighter-rouge">test_behavior1</code> and <code class="language-plaintext highlighter-rouge">test_behavior2</code>, it will result in a failure in <code class="language-plaintext highlighter-rouge">test_behavior5</code> because <code class="language-plaintext highlighter-rouge">self.helper.remove_content(valueB)</code> will end up throwing an error!</p>

<p>Furthermore, for anyone reading these tests, it is not entirely clear that <code class="language-plaintext highlighter-rouge">test_behavior1</code>, and <code class="language-plaintext highlighter-rouge">test_behavior2</code> need <code class="language-plaintext highlighter-rouge">self.helper</code> to be initialized with values <code class="language-plaintext highlighter-rouge">[valueA, valueB]</code>, but do not need for <code class="language-plaintext highlighter-rouge">controllerA</code> in <code class="language-plaintext highlighter-rouge">self.helper</code>. The preconditions for <code class="language-plaintext highlighter-rouge">test_behavior1</code> and <code class="language-plaintext highlighter-rouge">test_behavior2</code> are coupled with the preconditions for <code class="language-plaintext highlighter-rouge">test_behavior3</code>.</p>

<p>It also results in test incompleteness in that, if we introduce a bug that causes <code class="language-plaintext highlighter-rouge">behavior1</code> to fail when <code class="language-plaintext highlighter-rouge">self.helper.add_controller(controllerA)</code> is not set, we might not catch that bug because we have initialized the test for <code class="language-plaintext highlighter-rouge">behavior1</code> with <code class="language-plaintext highlighter-rouge">self.helper.add_controller(controllerA)</code>.</p>

<h3 id="how-to-decouple-such-tests">How to decouple such tests?</h3>

<p>Use the <code class="language-plaintext highlighter-rouge">setUp</code> method to simply set up your dependencies, but not to enforce any precondition. Instead, make setting preconditions part of the <em>arrange</em> step of each unit test. You can even encapsulate the precondition setting into a function (with the right parameters) so that the <em>arrange</em> section does not get too bloated, and yet the test code is readable. Consider the following refactoring of the tests:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SUTTestCase</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">setUp</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">StubHelper</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sut</span> <span class="o">=</span> <span class="nc">SUT</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">prepare_helper</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">contents</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="n">Value</span><span class="p">],</span> <span class="n">controller</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Controller</span><span class="p">]</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span> <span class="o">=</span> <span class="nc">StubHelper</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">.</span><span class="nf">add_contents</span><span class="p">(</span><span class="n">contents</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">controller</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">helper</span><span class="p">.</span><span class="nf">add_controller</span><span class="p">(</span><span class="n">controller</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">test_behavior1</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Assumes self.helper is a fresh object.
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">prepare_helper</span><span class="p">(</span><span class="n">contents</span><span class="o">=</span><span class="p">[</span><span class="n">valueA</span><span class="p">,</span> <span class="n">valueB</span><span class="p">])</span>
        <span class="bp">...</span>

    <span class="k">def</span> <span class="nf">test_behavior2</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Assumes self.helper is a fresh object.
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">prepare_helper</span><span class="p">(</span><span class="n">contents</span><span class="o">=</span><span class="p">[</span><span class="n">valueA</span><span class="p">,</span> <span class="n">valueB</span><span class="p">])</span>
        <span class="p">...</span>    

    <span class="k">def</span> <span class="nf">test_behavior3</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Assumes self.helper is a fresh object.
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">prepare_helper</span><span class="p">(</span><span class="n">contents</span><span class="o">=</span><span class="p">[</span><span class="n">valueA</span><span class="p">,</span> <span class="n">valueB</span><span class="p">],</span> <span class="n">controller</span><span class="o">=</span><span class="n">controllerA</span><span class="p">)</span>
        <span class="bp">...</span>

    <span class="k">def</span> <span class="nf">test_behavior4</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Assumes self.helper is a fresh object.
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">prepare_helper</span><span class="p">(</span><span class="n">contents</span><span class="o">=</span><span class="p">[</span><span class="n">valueA</span><span class="p">,</span> <span class="n">valueB</span><span class="p">],</span> <span class="n">controller</span><span class="o">=</span><span class="n">controllerA</span><span class="p">)</span>
        <span class="bp">...</span>

    <span class="k">def</span> <span class="nf">test_behavior5</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Assumes self.helper is a fresh object.
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">prepare_helper</span><span class="p">(</span><span class="n">contents</span><span class="o">=</span><span class="p">[</span><span class="n">valueA</span><span class="p">],</span> <span class="n">controller</span><span class="o">=</span><span class="n">controllerA</span><span class="p">)</span>
        <span class="bp">...</span>
</code></pre></div></div>

<h2 id="coupling-in-parameterized-tests">Coupling in parameterized tests</h2>

<p><a href="https://dl.acm.org/doi/10.1145/1095430.1081749">Parameterized tests</a> are a collection of tests that run the same verification, but with different inputs. While this is a very useful feature (available in almost all unit test frameworks), it is also very easy to abuse. A few common ways I have seen it abused is in conjunction with <a href="https://srikanth.sastry.name/dry-unit-tests-are-bad/">DRYing</a>, and the use ‚Äòif‚Äô checks, and that often results in coupling all the tests denoted by the parameterized list. Consider the following illustration:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TestOutput</span><span class="p">(</span><span class="n">typing</span><span class="p">.</span><span class="n">NamedTuple</span><span class="p">):</span>
    <span class="n">status</span><span class="p">:</span> <span class="n">StatusEnum</span>
    <span class="n">return_value</span><span class="p">:</span> <span class="n">typing</span><span class="p">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="n">exception</span><span class="p">:</span> <span class="n">typing</span><span class="p">.</span><span class="n">Optional</span><span class="p">[</span><span class="nb">Exception</span><span class="p">]</span>
    <span class="bp">...</span>

<span class="k">class</span> <span class="nc">TestSequence</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
  
    <span class="nd">@parameterized.expand</span><span class="p">([</span>
        <span class="p">[</span><span class="n">test_input1</span><span class="p">,</span> <span class="n">expected_output1</span><span class="p">],</span>
        <span class="p">[</span><span class="n">test_input2</span><span class="p">,</span> <span class="n">expected_output2</span><span class="p">],</span>
        <span class="bp">...</span>
    <span class="p">])</span>
    <span class="k">def</span> <span class="nf">test_something</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">test_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">:</span> <span class="n">TestOutput</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_run_test</span><span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_run_test</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">test_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">:</span> <span class="n">TestOutput</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">sut</span> <span class="o">=</span> <span class="nc">SUT</span><span class="p">(...)</span>
        <span class="nf">prepare_sut_for_tests</span><span class="p">(</span><span class="n">sut</span><span class="p">,</span> <span class="n">test_input</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">sut</span><span class="p">.</span><span class="nf">do_something</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
        <span class="n">test_output</span> <span class="o">=</span> <span class="nf">make_test_output</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">sut</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEquals</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">test_output</span><span class="p">)</span>

</code></pre></div></div>

<p>The above illustration tests the method <code class="language-plaintext highlighter-rouge">do_something</code> for various possible inputs. However, note that the outputs (as illustrated in the class <code class="language-plaintext highlighter-rouge">TestOutput</code> can have a <code class="language-plaintext highlighter-rouge">status</code>, a <code class="language-plaintext highlighter-rouge">return_value</code>, or an <code class="language-plaintext highlighter-rouge">exception</code>). This means that every instantiation (for each parameter) has to content with the possibility of different types of outputs even though any single test only should have to verify against a single type of output. This couples all the tests verifying <code class="language-plaintext highlighter-rouge">do_something</code>, this making it difficult to read and understand. Adding a new test case here becomes tricky because any changes to either <code class="language-plaintext highlighter-rouge">prepare_sut_for_tests</code>, or <code class="language-plaintext highlighter-rouge">make_test_output</code> now affects all the tests!</p>

<h3 id="how-to-decouple-parameterized-tests">How to decouple parameterized tests?</h3>

<p>There are some fairly straightforward ways to decouple such tests. First, is that we should be very conservative about how we organize these tests. For example, we can group all positive tests and group all negative tests separately; similarly, we can further subgroup the tests based on the type of assertions on the output. In the above example, we can have three subgroups: positive tests that verify only output status, positive tests that verify return value, and negative tests that verify exception. Thus you now have three parameterized test classes that look something like this:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TestDoSomething</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
  
    <span class="nd">@parameterized.expand</span><span class="p">([</span>
        <span class="p">[</span><span class="n">test_status_input1</span><span class="p">,</span> <span class="n">expected_status_output1</span><span class="p">],</span>
        <span class="p">[</span><span class="n">test_status_input2</span><span class="p">,</span> <span class="n">expected_status_output2</span><span class="p">],</span>
        <span class="bp">...</span>
    <span class="p">])</span>
    <span class="k">def</span> <span class="nf">test_something_status_only</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">test_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
        <span class="n">expected_output</span><span class="p">:</span> <span class="n">StatusEnum</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Arrange
</span>        <span class="n">sut</span> <span class="o">=</span> <span class="nc">SUT</span><span class="p">(...)</span>
        <span class="p">...</span>  <span class="c1"># More 'arrange' code
</span>        
        <span class="c1"># Act
</span>        <span class="n">output</span> <span class="o">=</span> <span class="n">sut</span><span class="p">.</span><span class="nf">do_something</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
        <span class="n">output_status</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">status</span>
        
        <span class="c1"># Assert
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">assertEquals</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">output_status</span><span class="p">)</span>
        
    <span class="nd">@parameterized.expand</span><span class="p">([</span>
        <span class="p">[</span><span class="n">test_return_value_input1</span><span class="p">,</span> <span class="n">expected_return_value_output1</span><span class="p">],</span>
        <span class="p">[</span><span class="n">test_return_value_input2</span><span class="p">,</span> <span class="n">expected_return_value_output2</span><span class="p">],</span>
        <span class="bp">...</span>
    <span class="p">])</span>
    <span class="k">def</span> <span class="nf">test_something_return_value_only</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">test_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
        <span class="n">expected_output</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Arrange
</span>        <span class="n">sut</span> <span class="o">=</span> <span class="nc">SUT</span><span class="p">(...)</span>
        <span class="p">...</span>  <span class="c1"># More 'arrange' code
</span>        
        <span class="c1"># Act
</span>        <span class="n">output</span> <span class="o">=</span> <span class="n">sut</span><span class="p">.</span><span class="nf">do_something</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
        <span class="n">output_status</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">status</span>
        <span class="n">output_value</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">value</span>
        
        <span class="c1"># Assert
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">assertEquals</span><span class="p">(</span><span class="n">SomeEnum</span><span class="p">.</span><span class="n">SUCCESS</span><span class="p">,</span> <span class="n">output_status</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEquals</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">output_value</span><span class="p">)</span>

    <span class="nd">@parameterized.expand</span><span class="p">([</span>
        <span class="p">[</span><span class="n">test_return_value_input1</span><span class="p">,</span> <span class="n">expected_error_code_output1</span><span class="p">],</span>
        <span class="p">[</span><span class="n">test_return_value_input2</span><span class="p">,</span> <span class="n">expected_error_code_output2</span><span class="p">],</span>
        <span class="bp">...</span>
    <span class="p">])</span>
    <span class="k">def</span> <span class="nf">test_something_throws_exception</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">test_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">expected_error_code</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Arrange
</span>        <span class="n">sut</span> <span class="o">=</span> <span class="nc">SUT</span><span class="p">(...)</span>
        <span class="p">...</span>  <span class="c1"># More 'arrange' code
</span>        
        <span class="c1"># Act
</span>        <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="nf">assertRaises</span><span class="p">(</span><span class="n">SomeSUTException</span><span class="p">)</span> <span class="k">as</span> <span class="n">exception_context</span><span class="p">:</span>
            <span class="n">sut</span><span class="p">.</span><span class="nf">do_something</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
        <span class="n">exception</span> <span class="o">=</span> <span class="n">exception_context</span><span class="p">.</span><span class="n">exception</span>
        
        <span class="c1"># Assert
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">assertEquals</span><span class="p">(</span><span class="n">excepted_error_code</span><span class="p">,</span> <span class="n">exception</span><span class="p">.</span><span class="n">error_code</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="Professional" /><category term="unit tests" /><category term="software engineering" /><summary type="html"><![CDATA[Almost by definition unit tests should be isolated from its (external, shared) dependencies. But, equally importantly, unit tests should also be isolated from each other. When one test starts to affect another test, the two tests are said to be coupled. Alternatively, if changes to one test can negatively impact the correctness of another test, then the two tests are said to be coupled.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://srikanth.sastry.name/images/carabiners-connected.jpg" /><media:content medium="image" url="https://srikanth.sastry.name/images/carabiners-connected.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">In unit tests, I favor Detroit over London</title><link href="https://srikanth.sastry.name/in-unit-tests-favor-detroit-over-london/" rel="alternate" type="text/html" title="In unit tests, I favor Detroit over London" /><published>2022-06-26T00:00:00+00:00</published><updated>2022-06-26T00:00:00+00:00</updated><id>https://srikanth.sastry.name/in-unit-tests-i-favor-detroit-over-london</id><content type="html" xml:base="https://srikanth.sastry.name/in-unit-tests-favor-detroit-over-london/"><![CDATA[<!-- ![](/images/detroit-wall-frame.jpg) -->

<p><a href="/defining-unit-tests-two-schools-of-thought/">Recall</a> the two schools of thought around unit test: Detroit, and London. Briefly, the Detroit school considers a ‚Äòunit‚Äô of software to be tested as a ‚Äòbehavior‚Äô that consists of one or more classes, and unit tests replace only shared and/or external dependencies with test doubles. In contrast, the London school consider a ‚Äòunit‚Äô to be a single class, and replaces all dependencies with test doubles.</p>

<table>
  <thead>
    <tr>
      <th>School</th>
      <th>Unit</th>
      <th>Isolation</th>
      <th>Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Detroit</td>
      <td>Behavior</td>
      <td>Replace shared and external dependencies with test doubles</td>
      <td>‚Äòfast‚Äô</td>
    </tr>
    <tr>
      <td>London</td>
      <td>Class</td>
      <td>Replace all dependencies (internal, external, shared, etc.) with test doubles</td>
      <td>‚Äòfast‚Äô</td>
    </tr>
  </tbody>
</table>

<p>See this <a href="/defining-unit-tests-two-schools-of-thought/">note</a> for a more detailed discussion on the two schools.</p>

<p>Each school have it‚Äôs proponents and each school of thought has it‚Äôs advantages. I, personally, prefer the Detroit school over the London school. I have noticed that following the Detroit school has made my test suite more <a href="/unit-test-attributes-and-their-trade-offs/">accurate and complete</a>.</p>

<h2 id="improved-accuracy-when-refactoring">Improved Accuracy (when refactoring)</h2>

<p>In <a href="/unit-test-attributes-and-their-trade-offs/">the post on attributes of a unit test suite</a>, I defined <em>accuracy</em> as the measure of how likely it is that a test failure denotes a bug in your diff. I have noticed that unit test suites that follow the Detroit school tended to have high accuracy when your codebase has a lot of classes that are public <em>de jour</em>, but private <em>de facto</em>.</p>

<p>Codebases I have worked in typically have hundreds of classes, but only a handful of those classes are actually referenced by external classes/services. Most of the classes are part of a private API that is internal to the service. Let‚Äôs take a concrete illustration. Say, there is a class <code class="language-plaintext highlighter-rouge">Util</code> that is used only by classes <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code> within the codebase, and has no other callers; in fact, <code class="language-plaintext highlighter-rouge">Util</code> exists only to help classes <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code> implement their respective user journies. Here although <code class="language-plaintext highlighter-rouge">Util</code> is a class with public methods, in reality <code class="language-plaintext highlighter-rouge">Util</code> really represents the common implementation details for <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code>.</p>

<h3 id="in-london">In London</h3>
<p>According to the London school, all unit tests for <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Fearure2</code> should be replacing <code class="language-plaintext highlighter-rouge">Util</code> with a test double. Thus, tests for <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code> look as follows.
<img src="/images/London-School-Accuracy-Before.png" alt="" /></p>

<p>Now, say we want to do some refactoring that spans <code class="language-plaintext highlighter-rouge">Feature1</code>, <code class="language-plaintext highlighter-rouge">Feature2</code>, and <code class="language-plaintext highlighter-rouge">Util</code>. Since <code class="language-plaintext highlighter-rouge">Util</code> is really has a private API with <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code>, we can change the API of <code class="language-plaintext highlighter-rouge">Util</code> in concert with <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code> in a single diff. Now, since the tests for <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code> use test doubles for <code class="language-plaintext highlighter-rouge">Util</code>, and we have changed <code class="language-plaintext highlighter-rouge">Util</code>‚Äôs API, we need to change the test doubles‚Äô implementation to match the new API. After making these changes, say, the tests for <code class="language-plaintext highlighter-rouge">Util</code> pass, but the tests for <code class="language-plaintext highlighter-rouge">Feature1</code> fail.</p>

<p><img src="/images/London-School-Accuracy-After.png" alt="" /></p>

<p>Now, does the test failure denote a bug in our refactoring, or does it denote an error in how we modified the tests? This is not easy to determine except by stepping through the tests manually. Thus, the test suite does not have high accuracy.</p>

<h3 id="in-detroit">In Detroit</h3>
<p>In contrast, according to the Detroit school, the unit tests for <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code> can use <code class="language-plaintext highlighter-rouge">Util</code> as such (without test doubles). The tests for <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code> look as follows.</p>

<p><img src="/images/Detroit-School-Accuracy-Before.png" alt="" /></p>

<p>If we do the same refactoring across <code class="language-plaintext highlighter-rouge">Feature1</code>, <code class="language-plaintext highlighter-rouge">Feature2</code>, and <code class="language-plaintext highlighter-rouge">Util</code> classes, note that we do not need to make any changes to the tests for <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code>. If the tests fail, then we have a very high signal that the refactoring has a bug in it; this makes for a high accuracy test suite!</p>

<p><img src="/images/Detroit-School-Accuracy-After.png" alt="" /></p>

<p>Furthermore, since <code class="language-plaintext highlighter-rouge">Util</code> exists only to serve <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code>, you can argue that <code class="language-plaintext highlighter-rouge">Util</code> doesn‚Äôt even need any unit tests of it‚Äôs own; the tests for <code class="language-plaintext highlighter-rouge">Feature1</code> and <code class="language-plaintext highlighter-rouge">Feature2</code> cover the spread!</p>

<h2 id="improved-completeness-around-regressions">Improved Completeness (around regressions)</h2>
<p>In <a href="/unit-test-attributes-and-their-trade-offs/">the post on attributes of a unit test suite</a>, I defined <em>completeness</em> as the measure of how likely a bug introduced by your diff is caught by your test suite. I have seen unit tests following the Detroit school catching bugs/regressions more easily, especially when the bugs are introduced by API contract violations.</p>

<p>It easier to see this with an example. Say, there is a class <code class="language-plaintext highlighter-rouge">Outer</code> that uses a class <code class="language-plaintext highlighter-rouge">Inner</code>, and <code class="language-plaintext highlighter-rouge">Inner</code> is an internal non-shared dependency. Let‚Äôs say that the class <code class="language-plaintext highlighter-rouge">Outer</code> depends on a specific contract, (let‚Äôs call it) alpha, that <code class="language-plaintext highlighter-rouge">Inner</code>‚Äôs API satisfies, for correctness. Recall that we practically trade off between the speed of a test suite and it‚Äôs completeness, let us posit that the incompleteness here is that we do not have a test for <code class="language-plaintext highlighter-rouge">Inner</code> satisfying contract alpha.</p>

<h3 id="in-london-1">In London</h3>

<p>Following the London school, the tests for <code class="language-plaintext highlighter-rouge">Outer</code> replace the instance of <code class="language-plaintext highlighter-rouge">Inner</code> with a test double, and since the test double is a replacement for <code class="language-plaintext highlighter-rouge">Inner</code>, it also satisfies contract alpha. See the illustration below for clarity.</p>

<p><img src="/images/London-School-Completeness-Before.png" alt="Image not found: /images/London-School-Completeness-Before.png" title="Image not found: /images/London-School-Completeness-Before.png" /></p>

<p>Now, let‚Äôs assume that we have a diff that ‚Äòrefactors‚Äô <code class="language-plaintext highlighter-rouge">Inner</code>, but in that process, it introduces a bug that violates contract alpha. Since we have assumed an incompleteness in our test suite around contract alpha, the unit test for <code class="language-plaintext highlighter-rouge">Inner</code> does not catch this regression. Also, since the tests for <code class="language-plaintext highlighter-rouge">Outer</code> use a test double for <code class="language-plaintext highlighter-rouge">Inner</code> (which satisfies contract alpha), those tests do not detect this regression either.</p>

<p><img src="/images/London-School-Completeness-After.png" alt="" /></p>

<h3 id="in-detroit-1">In Detroit</h3>

<p>If we were to follow the Detroit school instead, then the unit tests for <code class="language-plaintext highlighter-rouge">Outer</code> instantiate and use <code class="language-plaintext highlighter-rouge">Inner</code> when testing the correctness of <code class="language-plaintext highlighter-rouge">Outer</code>, as shown below. Note that the test incompletness w.r.t. contract alpha still exists.
<img src="/images/Detroit-School-Completeness-Before.png" alt="" /></p>

<p>Here, like before, assume that we have a diff that ‚Äòrefactors‚Äô <code class="language-plaintext highlighter-rouge">Inner</code> and breaks contract alpha. This time around, although the test suite for <code class="language-plaintext highlighter-rouge">Inner</code> does not catch the regression, the test suite for <code class="language-plaintext highlighter-rouge">Outer</code> will catch the regression. Why? Because the correctness of <code class="language-plaintext highlighter-rouge">Outer</code> depends on <code class="language-plaintext highlighter-rouge">Inner</code> satisfying contract alpha. When that contract is violated <code class="language-plaintext highlighter-rouge">Outer</code> fails to satisfy correctness, and is therefore, it‚Äôs unit tests fail/</p>

<p><img src="/images/Detroit-School-Completeness-After.png" alt="" /></p>

<p>In effect, even though we did not have an explicit test for contract alpha, the unit tests written according to the Detroit school tend to have better completeness than the ones written following the London school.</p>]]></content><author><name></name></author><category term="Professional" /><category term="unit tests" /><category term="software engineering" /><category term="london school" /><category term="detroit school" /><category term="classical school" /><category term="mockist school" /><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://srikanth.sastry.name/images/detroit-wall-frame.jpg" /><media:content medium="image" url="https://srikanth.sastry.name/images/detroit-wall-frame.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Defining unit tests: two schools of thought</title><link href="https://srikanth.sastry.name/defining-unit-tests-two-schools-of-thought/" rel="alternate" type="text/html" title="Defining unit tests: two schools of thought" /><published>2022-06-18T00:00:00+00:00</published><updated>2022-06-18T00:00:00+00:00</updated><id>https://srikanth.sastry.name/defining-unit-tests-two-schools-of-thought</id><content type="html" xml:base="https://srikanth.sastry.name/defining-unit-tests-two-schools-of-thought/"><![CDATA[<!-- ![](/images/london-detroit.jpg) -->

<h2 id="definitions-what-is-a-unit-test">Definitions: What is a unit test?</h2>

<p>There are several definitions for unit tests. <a href="https://www.artofunittesting.com/definition-of-a-unit-test">Roy Osherove</a> defines it as ‚Äúpiece of code that invokes a unit of work in the system and then checks a single assumption about the behavior of that unit of work‚Äù; Kent Beck turns the idea of defining unit tests on it‚Äôs head by <a href="https://tidyfirst.substack.com/p/desirable-unit-tests">simply stating a list of properties</a>, and any code that satisfies those properties in a ‚Äúunit test‚Äù.</p>

<p>I like Vladimir Khorikov‚Äôs definition of a unit test in his book <a href="https://www.manning.com/books/unit-testing">Unit Testing Principles, Practices, and Patterns</a>. According to him, a unit test is a piece of code that (1) verifies a unit of software, (2) in isolation, and (3) quickly. The above definition only balkanizes a <em>unit test</em> into three undefined terms: (1) unit of software, (2) isolation, and (3) quick/fast/speed. Of the three, the third one is the easiest to understand intuitively. Being <em>fast</em> simply means that you should be able to run the test in real time and get the results quickly enough to enable interactive iteration of modifying the unit of software you are changing. However, the other two terms: <em>unit of software</em>, and <em>isolation</em> merit more discussion.</p>

<h2 id="are-you-from-detroit-or-london">Are you from Detroit, or London?</h2>

<p>In fact, there are two schools of thought around how the above two terms should be defined. The ‚Äòoriginal/classic/Detroit‚Äô school, and the ‚Äòmockist/London‚Äô school. Not surprisingly, the school of thought you subscribe to has a significant impact on how you write unit tests. For a more detailed treatment of the two schools of thought, I suggest Martin Folwer‚Äôs <a href="https://martinfowler.com/articles/mocksArentStubs.html#ClassicalAndMockistTesting">excellent article on the subject of Mocks and Stubs</a>. Chapter 2 of Khorikov‚Äôs book <a href="https://www.manning.com/books/unit-testing">Unit Testing Principles, Practices, and Patterns</a> also has some good insights into it. I have distilled their contents as it pertains to unit test definitions.</p>

<h3 id="the-detroit-school">The Detroit School</h3>

<p>The Classical or Detroit school of thought originated with Kent Beck‚Äôs ‚Äú<a href="https://www.oreilly.com/library/view/test-driven-development/0321146530/">Test Driven Development</a>‚Äù.</p>

<p><strong>Unit of software.</strong> According to this school, the unit of software to test is a ‚Äúbehavior‚Äù. This behavior could be implemented in a single class, or a collection of classes. The important property here is that the the code that comprises the unit must be (1) internal to the software, (2) connected with each other in the dependency tree, and (3) not shared by another other part of the software.</p>

<p>Thus, a unit of software cannot include external entities such as databases, log servers, file systems etc. They also cannot include external (but local) libraries such as system time and timers. Importantly, it is <em>ok</em> to include a class that depends on another class via a private non-shared dependency.</p>

<p><strong>Isolation.</strong> Given the above notion of a ‚Äúunit‚Äù of software, isolation simply means that the test is not dependent on anything outside that unit of software. In practical terms, it means that a unit test needs to replace all external and shared dependencies with <a href="/mocks-stubs-andhow-to-use-them/">test doubles</a>.</p>

<h3 id="the-london-school">The London School</h3>

<p>The mockist or London school of thought was popularized by <a href="https://www.linkedin.com/in/stevefreeman">Steve Freeman</a> (<a href="https://twitter.com/sf105">twitter</a>) and <a href="http://www.natpryce.com/bio.html">Nat Pryce</a> in their book ‚Äú<a href="http://growing-object-oriented-software.com/">Growing Object- Oriented Software, Guided by Tests</a>‚Äù.</p>

<p><strong>Unit of Software.</strong> Given the heavy bias Object-Oriented software, unsurprisingly, the unit of software for a unit test is a single class (in some cases, it can be a single method). This is strictly so. ANy other class that this the ‚Äòclass under test‚Äô depends on cannot be part of the unit being tested.</p>

<p><strong>Isolation.</strong> What follows from the above notion of a ‚Äúunit‚Äù is that <em>everything</em> that is not the class under test must be replaced by test doubles. If you are instantiating another class inside the class under test, then you must replace that instantiation with an injected instance or a factory that can be replaced with a test double in the tests.</p>

<p>Here is a quick summary of the definitions of a unit tests under the two schools.</p>

<table>
  <thead>
    <tr>
      <th>School</th>
      <th>Unit</th>
      <th>Isolation</th>
      <th>Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Detroit</td>
      <td>Behavior</td>
      <td>Replace shared and external dependencies with test doubles</td>
      <td>‚Äòfast‚Äô</td>
    </tr>
    <tr>
      <td>London</td>
      <td>Class</td>
      <td>Replace all dependencies (internal, external, shared, etc.) with test doubles</td>
      <td>‚Äòfast‚Äô</td>
    </tr>
  </tbody>
</table>

<h2 id="what-does-this-mean">What does this mean?</h2>

<p>The school of thought you subscribe to can have a significant impact on your software design and testing. There is nothing I can say here that hasn‚Äôt already been explained by Martin Fowler in his article ‚Äú<a href="https://martinfowler.com/articles/mocksArentStubs.html">Mocks aren‚Äôt stubs</a>‚Äù. So, I highly recommend you read it for yourself.</p>]]></content><author><name></name></author><category term="Professional" /><category term="unit tests" /><category term="software engineering" /><category term="classical school" /><category term="detroit school" /><category term="london school" /><summary type="html"><![CDATA[A unit test is a piece of code that verifies a "unit" of software, in "isolation", and quickly. There are two schools of thought on the notion of "unit" and "isolation", and that makes all the difference.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://srikanth.sastry.name/images/london-detroit.jpg" /><media:content medium="image" url="https://srikanth.sastry.name/images/london-detroit.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Primary attributes of unit test suites and their tradeoffs</title><link href="https://srikanth.sastry.name/unit-test-attributes-and-their-trade-offs/" rel="alternate" type="text/html" title="Primary attributes of unit test suites and their tradeoffs" /><published>2022-06-13T00:00:00+00:00</published><updated>2022-06-13T00:00:00+00:00</updated><id>https://srikanth.sastry.name/unit-test-attributes-and-their-trade-offs</id><content type="html" xml:base="https://srikanth.sastry.name/unit-test-attributes-and-their-trade-offs/"><![CDATA[<!-- ![](/images/accuracy-completeness-speed.png) -->
<p>Unit test suites have three primary attributes.</p>

<ol>
  <li>accuracy,</li>
  <li>completeness, and</li>
  <li>speed.</li>
</ol>

<p><em>Accuracy</em> says that if a test fails, then there is a bug. <em>Completeness</em> says that if there is a bug, then a unit test will fail. <em>Speed</em> says that tests will run ‚Äòfast‚Äô. These three attributes are in opposition with each other, and you can only satisfy any two of the three attributes!</p>

<p>Before discussing these attributes, it is important to note that they are not properties of test suite at rest, but rather, of the test suite during changes. That is, these attributes are measured only when you are making changes to the code and running the test suite in response to those changes. Also, these attributes are not applicable to a single unit test. Instead, they apply to the test suite as a whole. Furthermore, the quality of your test suite is determined by how well the suite measures up along these attributes.</p>

<h3 id="attributes-descriptions">Attributes‚Äô descriptions</h3>
<p>Let‚Äôs describe each of these attributes, and then we can see any unit test suite is forced to trade off these attributes.</p>

<ol>
  <li><em>Accuracy.</em> It is a measure of robustness of the test suite to changes in the production code. If you make a change to the production code <em>without changing your unit tests</em>, and your test suite has a failure, then how likely is it that your changes introduced a bug? Accuracy is a measure of this likelihood. High quality unit tests typically have very good accuracy. If your test suite has poor accuracy, then it suggests that either your tests are brittle, they are actually testing implementation details instead of functionality, or your production code is poorly designed with leaky abstractions. Inaccurate tests reduce your ability to detect regressions. They fail to provide early warning when a diff breaks existing functionality (because the developer cannot be sure that the test failure is a genuine bug, and not an artifact of test brittleness). As a result, developers are more likely to ignore test failure, or modify the tests to make it ‚Äòpass‚Äô, and thus introduce bugs in their code.</li>
  <li><em>Completeness</em>. This is a measure of how comprehensive the test suite really is. If you make a change to the production code <em>without changing your unit tests</em>, and you introduce a bug in <em>an existing functionality</em>, then how likely is it that your test suite will fail? Completeness is a measure of this likelihood. A lot of the test coverage metrics try to mimic the completeness of your test suite. However, <a href="/do-not-index-in-test-coverage/">we have seen how coverage metrics are often a poor proxy for completeness</a>.</li>
  <li><em>Speed</em>. This is simply a measure of how quickly a test suite runs. If tests are hermetic with the right use of <a href="/mocks-stubs-andhow-to-use-them/">test doubles</a>, then each test runs pretty quickly. However, if the tests are of poor quality or the test suite is very large, then they can get pretty slow. It is most noticeable when you are iterating on a feature, and with each small change, you need to run the test suite that seems to take forever to complete. Slow tests can have a disproportionate impact on developer velocity. It will make developer less likely to run tests eagerly, it increases the time between iterations, and it increases the CI/CD latency to where the gap between your code landing and the changes making it to prod can be unreasonably large. If this gets bad enough, it will discourage developers from running tests as needed, and thus allow bugs to creep in.</li>
</ol>

<h3 id="attribute-constraints-and-trade-offs">Attribute constraints and trade offs</h3>

<p>There is a tension among attributes, and how these attributes contribute to overall unit test suite quality.</p>

<p>Among accuracy, completeness, and speed, you cannot maximize all three; that is, you cannot have a <em>fast</em> test suite that will fail if <em>and only if</em> there is a bug. Maximizing any two will minimize the third.</p>
<ul>
  <li>A prefect test suite with high accuracy and completeness will inevitably be huge, and thus very slow.</li>
  <li>A fast test suite with high accuracy will often only test only the most common user journeys, and thus be incomplete.</li>
  <li>A test suite with very high coverage is often made ‚Äòfast‚Äô through extensive use of test doubles and ends up coupling tests with the implementation details, which makes the tests brittle, and therefore inaccurate.</li>
</ul>

<h3 id="whats-the-right-trade-off">What‚Äôs the right trade off?</h3>
<p><img src="/images/balance-scale.jpg" alt="Image not found: /images/balance-scale.jpg" title="Image not found: /images/balance-scale.jpg" /></p>

<p>A natural follow up to the trade offs among accuracy, completeness, and speed is <em>‚ÄúWhat is the right trade off?‚Äù</em>. It helps to notice that, empirically, we are always making this trade off and naturally settling on some point in the trade-off surface. What is this natural resting point for these trade offs? Let‚Äôs examine a few things to help us answer the above question.</p>

<ol>
  <li>From experience, we know that bugs in software are inevitable, and we have learned to deal with it. While bug-free code might be the ideal, no one reasonably expects bug-free software, and we accept some level of incorrectness in our implementations.</li>
  <li>Flaky/brittle tests can have very significant negative consequences. Such tests are inherently untrustworthy, and therefore, serve no useful purpose. In the end, we tend to ignore such tests, and for all practical purposes they just don‚Äôt exist in our test suite.</li>
  <li>While extremely slow tests are an issue, we have figured out ways to improve test speeds through infrastructure developments. For instance,our CI/CD systems can run multiple tests in the test suite in parallel, and thus we are delayed only by the slowests tests in the test suite; we have figured out how to prune the affected tests in a diff by being smart about the build and test targets affected by the changes, and thus, we need not run the entire test suite for a small change; the machines that execute tests have just gotten faster, thus alleviating some of the latency issues, etc.</li>
</ol>

<p>From the above three observations, we can reasonably conclude that we cannot sacrifice accuracy. Accurate tests are the bedrock of trustworthy (and therefore, useful) test suites. Once we maximize accuracy, that leaves us with completeness and speed. Here there is a sliding scale between completeness and speed, and we could potentially rest anywhere on this scale.</p>

<p>So, is it ok to rest anywhere on the tradeoff spectrum between completeness and accuracy? Not quite. If you dial completeness all the way up and ignore speed, then you end up with a test suite that no one wants to run, and therefore, not useful at all. On the other hand, if you ignore completeness in favor of speed, then you are likely going to see a lot of regressions in your software and completely undermine consumer confidence in your product/service. In effect, <strong>the quality of your test suite is determined by the lowest score among the three attributes.</strong> Therefore, it is important to rest between completeness and speed, depending on the tolerance to errors and the minimum developer velocity you can sustain. For instance, if you are developing software for medical imaging, then your tolerance to errors is very very low, and so you should be favoring completeness at the expense of speed (and this is evident in how long it takes to make changes to software in the area of medical sciences). On the other hand, if you are building a web service that can be rolled back to a safe state quickly and with minimal external damage, then you probably want to favor speed over completeness (but only to a point; remember that your test quality is now determined by the completeness, or the lack thereof).</p>

<p>Thus, in conclusion, always maximize accuracy, and trade off between completeness and speed, depending on your tolerance of failures in production.</p>]]></content><author><name></name></author><category term="Professional" /><category term="unit tests" /><category term="software engineering" /><summary type="html"><![CDATA[Unit test suites have three attributes: accuracy, completeness, and speed. You can maximize any two, but not all three. So how do you choose what to maximize?]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://srikanth.sastry.name/images/accuracy-completeness-speed.png" /><media:content medium="image" url="https://srikanth.sastry.name/images/accuracy-completeness-speed.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The big WHY about unit tests</title><link href="https://srikanth.sastry.name/the-big-why-about-unit-tests/" rel="alternate" type="text/html" title="The big WHY about unit tests" /><published>2022-06-06T00:00:00+00:00</published><updated>2022-06-06T00:00:00+00:00</updated><id>https://srikanth.sastry.name/the-big-why-about-unit-tests</id><content type="html" xml:base="https://srikanth.sastry.name/the-big-why-about-unit-tests/"><![CDATA[<!-- ![Why unit test?](/images/question_mark_person_leaning.png) -->
<p>When you ask ‚Äúwhy do we write need unit tests?‚Äù, you will get several answers including</p>
<ul>
  <li>To find common bugs in your code</li>
  <li><a href="/the-merits-of-unit-tests-part-2/">As protection against regression</a></li>
  <li><a href="/merits-of-unit-tests-part-1/">To act as a de facto documentation of your code</a></li>
  <li><a href="/the-merits-of-unit-tests-part-3/">To help improve software design</a></li>
  <li><a href="/unit-tests-ftw-part-4/">To help debug issues in production</a></li>
  <li><a href="/merits-of-unit-tests-part-5/">Improve your APIs‚Äô usability</a></li>
  <li>etc.</li>
</ul>

<p>These seems like a collection of very good reasons, but it seems inelegant to state that the common phenomenon of unit testing has such disparate causes. 
There must be a ‚Äòhigher‚Äô cause for writing unit tests. I argue that this cause is ‚Äúmaintainability‚Äù.</p>

<h3 id="maintainability">Maintainability</h3>
<p><img src="/images/website-wrench-cog.png" alt="Maintainable software" />
Here is a potentially provocative statement; ‚ÄúThe final cause of unit tests is software maintainability‚Äù.
To put it differently, if your software was immutable and could not be altered in any way, then that software does not need any unit tests.</p>

<p>Given that almost all software is mutable, unit tests exist to ensure that we can mutate the software to improve upon its utility in a sustainable manner. All the aforementioned answers to the question ‚Äúwhy do we write unit tests‚Äù are ultimately subsumed by the cause of maintainability.</p>

<ul>
  <li>Unit tests help you find bugs in your code, thus allowing safe mutations that add functionality.</li>
  <li>Unit tests protect against regression, especially when refactoring, thus allowing safe mutation of the software in preparation for functional changes.</li>
  <li>Unit tests act as de facto documentation. It allows developers who change the code to communicate across time and space on how best to use existing code for mutating other code.</li>
  <li>Unit tests help improve software design. It some code/class is difficult to unit test, then the software design is poor. So, you iterate until unit testing becomes easier.</li>
  <li>Unit test help improve the usability of your API. Unit tests are the first customers of your API. If unit tests using your API are inelegant, then you iterate towards more usuable APIs. A more usable API is often a more used API, and thus, aids software evolution.</li>
</ul>

<p>Interestingly, looking at maintainability as the primary motivation for unit tests allows us to look at some aspects of unit tests differently.</p>

<h3 id="looking-at-unit-tests-differently">Looking at unit tests differently</h3>

<h4 id="unit-tests-incur-a-maintenance-cost">Unit tests incur a maintenance cost.</h4>
<p><img src="/images/calculator-sheet.png" alt="" /></p>

<p>If it code incurs a maintenance cost, and unit tests help reduce that cost, then you can naturally ask the following; <em>since unit tests are also code, do they not incur a maintenance cost?</em></p>

<p>Obviously the answer to the question above is an unequivocal ‚Äúyes!‚Äù. Thus, unit tests are only useful if the cost of maintaining them DOES NOT EXCEED the savings they provide as a buttress against production code. This observation has significant implications for how to design and write unit tests. For instance, unit tests must be simple straight line code that is human readable, even at the expense of performance and redundancy. See the post on <a href="https://srikanth.sastry.name/dry-unit-tests-are-bad/">DRY unit tests</a> for a more detailed treatment on this topic.</p>

<h4 id="unit-tests-can-have-diminishing-returns">Unit tests can have diminishing returns.</h4>
<p><img src="/images/down-graph-arrow.png" alt="" /></p>

<p>If unit tests incur a maintenance cost, then their utility is the difference between the maintainability they provide and the cost they incur. Since software is a living/evolving entity, both this utility changes over time. Consequently, if you are not careful with your tests, then could become the proverbial Albatross across your neck.
   Consequently, it is important to tend to your unit test suite and pay attention when the utility of a test starts to diminish. Importantly, refactor your tests to ensure that you do not hit the point of diminishing, or even negative returns on your unit test.</p>

<h4 id="unit-tests-should-be-cognitively-simple">Unit tests should be cognitively simple.</h4>
<p><img src="/images/simple-chair-wall-painting-white.png" alt="" /></p>

<p>An almost necessary way to reduce the maintenance cost of a unit tests is to make it very simple to read and understand. It helps with maintenance in two ways. First, it makes it easy to understand the intent of the test, and the coverage that the test provides. Second, it makes it easy to modify the test (if needed) without having to worry about an unintended consequences such modifications might have; a degenerate case is that of tests that have hit the point of diminishing returns; more simple a test is, the easier it is to refactor and/or delete it. See the post on <a href="https://srikanth.sastry.name/dry-unit-tests-are-bad/">DRY unit tests</a> for mote details.</p>

<h4 id="a-bad-unit-test-is-worse-than-no-unit-test">A bad unit test is worse than no unit test.</h4>
<p><img src="/images/sad-face-spray-paint.png" alt="" /></p>

<p>If unit test incur a maintenance cost, then a bad unit test has all the costs associated with unit tests and none of the benefits. It is a net loss. Your code base is much better off without that unit test. In fact, a bad unit test can have an even higher cost if it sends developers on a wild goose chase looking for bugs when such unit tests fail. So, unless a unit test is of high quality, don‚Äôt bother with it. Just delete it.</p>

<h4 id="a-flaky-unit-test-is-the-worst">A flaky unit test is the worst.</h4>
<p><img src="/images/yes-no.png" alt="" /></p>

<p>This is a corollary of the previous observation, but deserves some explanation. Flaky tests have the side effect of undermining the trust in the entire test suite. If a test is flaky, then developers are more likely to ignore red builds, because ‚Äòthat flaky test is the culprit, and so the failure can be ignored‚Äô. However, inevitably, some legitimate failure does occur. But, at this point, developers have been conditioned to ignore build/test failures. Consequently, a buggy commit makes it‚Äôs way to prod and causes a regression, which would never have happened if you didn‚Äôt have that flaky test.</p>]]></content><author><name></name></author><category term="Professional" /><category term="unit tests" /><category term="testing" /><category term="software engineering" /><summary type="html"><![CDATA[The ultimate "why" for unit tests is maintainability. All the arguments for having robust, good quality unit tests comes down to the following. Unit tests help keep your production code maintainable. Looking at maintainability as the primary motivation for unit tests allows us to look at some aspects of unit tests differently.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://srikanth.sastry.name/images/question_mark_person_leaning.png" /><media:content medium="image" url="https://srikanth.sastry.name/images/question_mark_person_leaning.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>